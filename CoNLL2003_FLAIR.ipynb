{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A05XPJJsDS7C"
   },
   "source": [
    "## FLAIR - NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@inproceedings{akbik2019flair,\n",
    "               title={FLAIR: An easy-to-use framework for state-of-the-art NLP},\n",
    "               author={Akbik, Alan and Bergmann, Tanja and Blythe, Duncan and Rasul, Kashif and Schweter, Stefan and Vollgraf, Roland},\n",
    "               booktitle={{NAACL} 2019, 2019 Annual Conference of the North American Chapter of the Association for Computational Linguistics (Demonstrations)},\n",
    "               pages={54--59},\n",
    "               year={2019}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a model that could find entities from the given piece of text, we first need to create a **training corpus**. Flair has a **specific structure** in which it expects the corpus to be. As per its documentation, it looks like:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5jNLy-myDZid"
   },
   "source": [
    "George N B-PER \n",
    "\n",
    "Washington N I-PER\n",
    "\n",
    "went V O\n",
    "\n",
    "to P O \n",
    "\n",
    "Washington B B-LOC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X6sWGA3PD_wL"
   },
   "source": [
    "The sentences in the corpus are separated by an empty line.\n",
    "Each row(line) has three columns. The first column is the word, the second column is the corresponding POS tag and the final column denotes the BIO-annotated NER tag.\n",
    "We need not have all these three columns, say we need to train the model to just predict the NER tags, we can omit the second column.\n",
    "The important thing to note here is, that the datasets that are available within flair.datasets and the other sequence labeling datasets should be in the given format. If we are training for custom entities, we need to prepare that dataset on our own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yZpJy3cEIyh"
   },
   "source": [
    "## DATA CREATION:\n",
    "flair.datasets has this class called **ColumnCorpus** using which **we can create our corpus object**. As you see the arguments for it’s __init__ method, the three .txt files which correspond to train, test and validation corpora, have the data in the format we discussed above. columns is a dictionary where we define the columns in the text files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRPVHmZtFFm6"
   },
   "source": [
    "Given that annotations are available in a certain format, the following piece of code could be modified as per the requirement. The following code is written assuming the data is in form of a pandas dataframe with two major columns, first being the actual text, the second is the annotation, that is a list of tuples, where the tuple has two elements, the first is the annotated text and the second is the corresponding label.\n",
    "Ideally, the text should just be a sentence, if not(is a paragraph), any sentence tokenizer could be used, for example, spaCy’s sentence tokenizer to get the text to sentence level. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXW6q3FyFUql"
   },
   "source": [
    "The following code will create a .txt file for the data given, hence could be called thrice to create the train, test and validation data in the required input format. This will save the .txt at the given path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3DBh5UwrEEXX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from difflib import SequenceMatcher\n",
    "import re\n",
    "import pickle\n",
    "\n",
    "def matcher(string, pattern):\n",
    "    '''\n",
    "    Return the start and end index of any pattern present in the text.\n",
    "    '''\n",
    "    match_list = []\n",
    "    pattern = pattern.strip()\n",
    "    seqMatch = SequenceMatcher(None, string, pattern, autojunk=False)\n",
    "    match = seqMatch.find_longest_match(0, len(string), 0, len(pattern))\n",
    "    if (match.size == len(pattern)):\n",
    "        start = match.a\n",
    "        end = match.a + match.size\n",
    "        match_tup = (start, end)\n",
    "        string = string.replace(pattern, \"X\" * len(pattern), 1)\n",
    "        match_list.append(match_tup)\n",
    "        \n",
    "    return match_list, string\n",
    "\n",
    "def mark_sentence(s, match_list):\n",
    "    '''\n",
    "    Marks all the entities in the sentence as per the BIO scheme. \n",
    "    '''\n",
    "    word_dict = {}\n",
    "    for word in s.split():\n",
    "        word_dict[word] = 'O'\n",
    "        \n",
    "    for start, end, e_type in match_list:\n",
    "        temp_str = s[start:end]\n",
    "        tmp_list = temp_str.split()\n",
    "        if len(tmp_list) > 1:\n",
    "            word_dict[tmp_list[0]] = 'B-' + e_type\n",
    "            for w in tmp_list[1:]:\n",
    "                word_dict[w] = 'I-' + e_type\n",
    "        else:\n",
    "            word_dict[temp_str] = 'B-' + e_type\n",
    "    return word_dict\n",
    "\n",
    "def clean(text):\n",
    "    '''\n",
    "    Just a helper fuction to add a space before the punctuations for better tokenization\n",
    "    '''\n",
    "    filters = [\"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"/\", \"*\", \".\", \":\", \";\", \"<\", \"=\", \">\", \"?\", \"@\", \"[\",\n",
    "               \"\\\\\", \"]\", \"_\", \"`\", \"{\", \"}\", \"~\", \"'\"]\n",
    "    for i in text:\n",
    "        if i in filters:\n",
    "            text = text.replace(i, \" \" + i)\n",
    "            \n",
    "    return text\n",
    "\n",
    "def create_data(df, filepath):\n",
    "    '''\n",
    "    The function responsible for the creation of data in the said format.\n",
    "    '''\n",
    "    with open(filepath , 'w') as f:\n",
    "        for text, annotation in zip(df.text, df.annotation):\n",
    "            text = clean(text)\n",
    "            text_ = text        \n",
    "            match_list = []\n",
    "            for i in annotation:\n",
    "                a, text_ = matcher(text, i[0])\n",
    "                match_list.append((a[0][0], a[0][1], i[1]))\n",
    "\n",
    "            d = mark_sentence(text, match_list)\n",
    "\n",
    "            for i in d.keys():\n",
    "                f.writelines(i + ' ' + d[i] +'\\n')\n",
    "            f.writelines('\\n')\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10a9XTA-Fyh3"
   },
   "source": [
    "## READING THE CORPUS\n",
    "It is ready to load the corpus we have created and begin with the training. Let’s start with loading our corpus.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "M9ib6HivFx-W",
    "outputId": "43bb9c13-7e6f-4690-9655-c62962f6d9ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-29 09:36:23,124 Reading data from C:\\Users\\Chiara\\Desktop\\CoNLL_project\n",
      "2021-03-29 09:36:23,127 Train: C:\\Users\\Chiara\\Desktop\\CoNLL_project\\train.txt\n",
      "2021-03-29 09:36:23,127 Dev: C:\\Users\\Chiara\\Desktop\\CoNLL_project\\valid.txt\n",
      "2021-03-29 09:36:23,128 Test: C:\\Users\\Chiara\\Desktop\\CoNLL_project\\test.txt\n"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "#get corpus and define columns\n",
    "\n",
    "data_folder=r'C:\\Users\\Chiara\\Desktop\\CoNLL_project'\n",
    "\n",
    "columns= {0:'text',1:'pos',2:\"phrase\",3:\"ner\"}\n",
    "\n",
    "corpus: Corpus = ColumnCorpus(data_folder,columns,\n",
    "                              train_file='train.txt',\n",
    "                              test_file='test.txt',\n",
    "                              dev_file='valid.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "RXxeS6ACGApf",
    "outputId": "1d3a6e2e-f30f-44a8-b38f-c513090667fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14987\n",
      "-DOCSTART-\n"
     ]
    }
   ],
   "source": [
    "#Now that we have loaded our corpus, we can use this corpus object to get its information like:\n",
    "print(len(corpus.train))\n",
    "\n",
    "#print(corpus.train[50].to_tagged_string('pos'))\n",
    "print(corpus.train[40].to_tagged_string('ner')) #50 is the number of the sentence that, for example, I want to analyse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "6WbHPJz9V_eo",
    "outputId": "fb15aab4-baeb-4b78-ba3b-74280f0fcdeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-29 09:36:30,466 --------------------------------------------------------------------------------\n",
      "2021-03-29 09:36:30,468 The model key 'ner' now maps to 'https://huggingface.co/flair/ner-english' on the HuggingFace ModelHub\n",
      "2021-03-29 09:36:30,469  - The most current version of the model is automatically downloaded from there.\n",
      "2021-03-29 09:36:30,470  - (you can alternatively manually download the original model at https://nlp.informatik.hu-berlin.de/resources/models/ner/en-ner-conll03-v0.4.pt)\n",
      "2021-03-29 09:36:30,471 --------------------------------------------------------------------------------\n",
      "2021-03-29 09:36:31,245 loading file C:\\Users\\Chiara\\.flair\\models\\ner-english\\4f4cdab26f24cb98b732b389e6cebc646c36f54cfd6e0b7d3b90b25656e4262f.8baa8ae8795f4df80b28e7f7b61d788ecbb057d1dc85aacb316f1bd02837a4a4\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from ipywidgets import IntProgress\n",
    "# make a sentence\n",
    "sentence = Sentence('I live in Paris')\n",
    "tagger = SequenceTagger.load('ner')\n",
    "tagger.predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MKS6orJMpxWO"
   },
   "source": [
    "Named entity recognition is a task that is well-suited to the type of **classifier-based approach**. In particular, a tagger can be built that labels each word in a sentence using the **IOB** format, where chunks are labelled by their appropriate type.\n",
    "\n",
    "\n",
    "The **IOB Tagging system** contains tags of the form:\n",
    "\n",
    "B - {CHUNK_TYPE} – for the word in the Beginning chunk\n",
    "\n",
    "I - {CHUNK_TYPE} – for words Inside the chunk\n",
    "\n",
    "O – Outside any chunk\n",
    "\n",
    "The IOB tags are further classified into the following classes :\n",
    "\n",
    "geo = Geographical Entity \n",
    "\n",
    "org = Organization\n",
    "\n",
    "per = Person\n",
    "\n",
    "gpe = Geopolitical Entity\n",
    "\n",
    "tim = Time indicator\n",
    "\n",
    "art = Artifact\n",
    "\n",
    "eve = Event\n",
    "\n",
    "nat = Natural Phenomenon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "31RhkoXCGWmb"
   },
   "source": [
    "## TRAINING:\n",
    "Continuing further, the next thing is to define the tag we want our model to be able to predict and create the tag dictionary, which is just all the available labels in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "D1ezJ0iDGWC8",
    "outputId": "866bfe61-e798-4823-ab2d-4b9dfbbdbff1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary with 12 tags: <unk>, O, B-ORG, B-MISC, B-PER, I-PER, B-LOC, I-ORG, I-MISC, I-LOC, <START>, <STOP>\n"
     ]
    }
   ],
   "source": [
    "# 2.tag to predict\n",
    "tag_type = 'ner'\n",
    "# 3.make tag dictionary from the corpus\n",
    "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)\n",
    "print(tag_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jX-CItIHGhtw"
   },
   "source": [
    "Next thing is to take care of the **embeddings**. The beauty of flair is in what all it lets you do with the embeddings. You can choose from the **bunch of pre-trained models** to create embeddings, even stack the said flair embeddings with powerful BERT, ELMO, and whatnot using the StackedEmbedding class. And obviously, train your own embeddings. The details of embeddings are  documented here https://github.com/flairNLP/flair/blob/master/resources/docs/TUTORIAL_3_WORD_EMBEDDING.md\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T0gLvgSjo8FI"
   },
   "source": [
    "**Stacked Embeddings**: Here, we can combine multiple embeddings to build a powerful word representation model without much complexity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 694,
     "referenced_widgets": [
      "27d097e601a44a46b62d47ca724a1004",
      "2ca72065e98c4508b6493d88b8d083ae",
      "51a9935a5d8d45cfb501cdc6540f75a5",
      "c67d1b8e46c54c8ea8e263c734f26e92",
      "903fdf14332f4b8fa7ab675f451c3a5f",
      "2a228686038c4a558f794cc855e9d8aa",
      "c10ef35584874e849c23015dfaeb87ea",
      "e8efbd4d62674de6af3932662c711014",
      "e2f9e731f21645d9a3facaaed38bbcdf",
      "da9b767d5b524e4dabe50048b4e9a70a",
      "97f24f08a89a4e509c5b3dc891d423ad",
      "2fb07d95d5f94b0bb830f1b9c291a344",
      "490c0d13e3034530b24769efc54ee050",
      "3bb3e89764b349a9aa3438237c802a03",
      "865e9d807af148e1949d863154197479",
      "533bf5168f18464eac9bca781e172202",
      "e5d48bfa1646405caf043329f43f595c",
      "e1828bd117444dafb6922ca3e03e7f8a",
      "343d7d1cd58f4129954add7f94b26258",
      "8aaa8ae9d7574c09b05696bcc2709870",
      "6bd598f6a12343439d9863f1d93005a9",
      "ffdd165c97a44b7094bc9bce7f53a625",
      "c85150bdaf6d444ab0a64d4962f6ea7c",
      "182f4066c27642b58b211612289c27af"
     ]
    },
    "id": "atFdoWsSJ-Sz",
    "outputId": "918835df-2dac-486d-b0b6-2f4e8c352d9d"
   },
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, StackedEmbeddings, TokenEmbeddings,TransformerWordEmbeddings\n",
    "from typing import List\n",
    "\n",
    "\n",
    "##bert_embedding = BertEmbedding()\n",
    "\n",
    "#4.initialize embeddings\n",
    "embedding_types : List[TokenEmbeddings] = [\n",
    "        WordEmbeddings('glove'),\n",
    "        TransformerWordEmbeddings('bert-base-uncased')]\n",
    "        ## other embeddings # comment in this line to use character embeddings\n",
    "    # CharacterEmbeddings(),\n",
    "\n",
    "    # comment in these lines to use flair embeddings\n",
    "    # FlairEmbeddings('news-forward'),\n",
    "    # FlairEmbeddings('news-backward'),]\n",
    "\n",
    "embeddings: StackedEmbeddings = StackedEmbeddings(embeddings=embedding_types)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "obqQZ5QuKdpU"
   },
   "source": [
    "The next step is to initialize the **Sequence Tagger**. Conceptually speaking, **what is trained in the backend is a bi-directional LSTM**. Flair lets you pass a flag to use the conditional random fields as well. Let’s define the said tagger and see the architecture too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PEHW5KDzKAdH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('glove')\n",
      "    (list_embedding_1): TransformerWordEmbeddings(\n",
      "      (model): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=868, out_features=868, bias=True)\n",
      "  (rnn): LSTM(868, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=12, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "#5. inintialize sequence tagger\n",
    "tagger : SequenceTagger = SequenceTagger(hidden_size=256,\n",
    "                                       embeddings=embeddings,\n",
    "                                       tag_dictionary=tag_dictionary,\n",
    "                                       tag_type=tag_type,\n",
    "                                       use_crf=True) #CRF\n",
    "print(tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Ome2Co-dVsqD"
   },
   "outputs": [],
   "source": [
    "##20 EPOCHS\n",
    "#from flair.trainers import ModelTrainer\n",
    "#6. initialize trainer\n",
    "#trainer : ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "#7.start training con 20 epoche dopo aver provato con 50 e avere notato che dopo la 20 inizia ad overfittare\n",
    "#trainer.train('gdrive/My Drive/TESI/FLAIR',\n",
    "              #learning_rate=0.1,\n",
    "              #mini_batch_size=32,\n",
    "              #max_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnfK0gKeLUWE"
   },
   "source": [
    "bi-directional LSTM:https://en.wikipedia.org/wiki/Bidirectional_recurrent_neural_networks\n",
    "conditional random fields: https://en.wikipedia.org/wiki/Conditional_random_field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "_hOQRJyCKofz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-29 09:36:45,945 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 09:36:45,951 Model: \"SequenceTagger(\n",
      "  (embeddings): StackedEmbeddings(\n",
      "    (list_embedding_0): WordEmbeddings('glove')\n",
      "    (list_embedding_1): TransformerWordEmbeddings(\n",
      "      (model): BertModel(\n",
      "        (embeddings): BertEmbeddings(\n",
      "          (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "          (position_embeddings): Embedding(512, 768)\n",
      "          (token_type_embeddings): Embedding(2, 768)\n",
      "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (encoder): BertEncoder(\n",
      "          (layer): ModuleList(\n",
      "            (0): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (1): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (2): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (3): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (4): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (5): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (6): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (7): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (8): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (9): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (10): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (11): BertLayer(\n",
      "              (attention): BertAttention(\n",
      "                (self): BertSelfAttention(\n",
      "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "                (output): BertSelfOutput(\n",
      "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                  (dropout): Dropout(p=0.1, inplace=False)\n",
      "                )\n",
      "              )\n",
      "              (intermediate): BertIntermediate(\n",
      "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              )\n",
      "              (output): BertOutput(\n",
      "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (pooler): BertPooler(\n",
      "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (activation): Tanh()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (word_dropout): WordDropout(p=0.05)\n",
      "  (locked_dropout): LockedDropout(p=0.5)\n",
      "  (embedding2nn): Linear(in_features=868, out_features=868, bias=True)\n",
      "  (rnn): LSTM(868, 256, batch_first=True, bidirectional=True)\n",
      "  (linear): Linear(in_features=512, out_features=12, bias=True)\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-03-29 09:36:45,952 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 09:36:45,953 Corpus: \"Corpus: 14987 train + 3466 dev + 3684 test sentences\"\n",
      "2021-03-29 09:36:45,955 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 09:36:45,956 Parameters:\n",
      "2021-03-29 09:36:45,957  - learning_rate: \"0.1\"\n",
      "2021-03-29 09:36:45,958  - mini_batch_size: \"32\"\n",
      "2021-03-29 09:36:45,960  - patience: \"3\"\n",
      "2021-03-29 09:36:45,961  - anneal_factor: \"0.5\"\n",
      "2021-03-29 09:36:45,964  - max_epochs: \"50\"\n",
      "2021-03-29 09:36:45,965  - shuffle: \"True\"\n",
      "2021-03-29 09:36:45,967  - train_with_dev: \"False\"\n",
      "2021-03-29 09:36:45,968  - batch_growth_annealing: \"False\"\n",
      "2021-03-29 09:36:45,969 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 09:36:45,970 Model training base path: \"C:\\Users\\Chiara\\Desktop\\CoNLL_project\"\n",
      "2021-03-29 09:36:45,971 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 09:36:45,972 Device: cpu\n",
      "2021-03-29 09:36:45,973 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 09:36:45,975 Embeddings storage mode: cpu\n",
      "2021-03-29 09:36:45,985 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 09:39:11,577 epoch 1 - iter 46/469 - loss 8.20853806 - samples/sec: 10.11 - lr: 0.100000\n",
      "2021-03-29 09:41:40,221 epoch 1 - iter 92/469 - loss 6.05806211 - samples/sec: 9.90 - lr: 0.100000\n",
      "2021-03-29 09:43:56,119 epoch 1 - iter 138/469 - loss 4.96416492 - samples/sec: 10.83 - lr: 0.100000\n",
      "2021-03-29 09:46:18,622 epoch 1 - iter 184/469 - loss 4.21762494 - samples/sec: 10.33 - lr: 0.100000\n",
      "2021-03-29 09:48:37,726 epoch 1 - iter 230/469 - loss 3.74924457 - samples/sec: 10.58 - lr: 0.100000\n",
      "2021-03-29 09:51:17,524 epoch 1 - iter 276/469 - loss 3.51860851 - samples/sec: 9.21 - lr: 0.100000\n",
      "2021-03-29 09:54:00,651 epoch 1 - iter 322/469 - loss 3.31445249 - samples/sec: 9.02 - lr: 0.100000\n",
      "2021-03-29 09:56:36,310 epoch 1 - iter 368/469 - loss 3.15419519 - samples/sec: 9.46 - lr: 0.100000\n",
      "2021-03-29 09:59:31,238 epoch 1 - iter 414/469 - loss 3.03530097 - samples/sec: 8.42 - lr: 0.100000\n",
      "2021-03-29 10:02:29,836 epoch 1 - iter 460/469 - loss 2.90873204 - samples/sec: 8.24 - lr: 0.100000\n",
      "2021-03-29 10:02:58,624 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:02:58,626 EPOCH 1 done: loss 2.8933 - lr 0.1000000\n",
      "2021-03-29 10:08:50,160 DEV : loss 1.0392283201217651 - score 0.8875\n",
      "2021-03-29 10:08:50,427 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-29 10:08:56,330 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:09:21,892 epoch 2 - iter 46/469 - loss 1.48723986 - samples/sec: 58.01 - lr: 0.100000\n",
      "2021-03-29 10:09:45,774 epoch 2 - iter 92/469 - loss 1.47088512 - samples/sec: 61.65 - lr: 0.100000\n",
      "2021-03-29 10:10:11,855 epoch 2 - iter 138/469 - loss 1.49438098 - samples/sec: 56.46 - lr: 0.100000\n",
      "2021-03-29 10:10:37,171 epoch 2 - iter 184/469 - loss 1.42660618 - samples/sec: 58.16 - lr: 0.100000\n",
      "2021-03-29 10:11:02,150 epoch 2 - iter 230/469 - loss 1.42999712 - samples/sec: 58.93 - lr: 0.100000\n",
      "2021-03-29 10:11:27,826 epoch 2 - iter 276/469 - loss 1.39485733 - samples/sec: 57.34 - lr: 0.100000\n",
      "2021-03-29 10:11:54,611 epoch 2 - iter 322/469 - loss 1.36685816 - samples/sec: 54.97 - lr: 0.100000\n",
      "2021-03-29 10:12:26,354 epoch 2 - iter 368/469 - loss 1.35406956 - samples/sec: 46.38 - lr: 0.100000\n",
      "2021-03-29 10:12:56,956 epoch 2 - iter 414/469 - loss 1.34358545 - samples/sec: 48.11 - lr: 0.100000\n",
      "2021-03-29 10:13:27,845 epoch 2 - iter 460/469 - loss 1.32759654 - samples/sec: 47.66 - lr: 0.100000\n",
      "2021-03-29 10:13:33,752 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:13:33,754 EPOCH 2 done: loss 1.3248 - lr 0.1000000\n",
      "2021-03-29 10:13:52,378 DEV : loss 0.7508131861686707 - score 0.9173\n",
      "2021-03-29 10:13:52,673 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-29 10:14:00,441 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:14:29,987 epoch 3 - iter 46/469 - loss 1.05067932 - samples/sec: 49.83 - lr: 0.100000\n",
      "2021-03-29 10:15:01,359 epoch 3 - iter 92/469 - loss 1.13674434 - samples/sec: 46.93 - lr: 0.100000\n",
      "2021-03-29 10:15:33,926 epoch 3 - iter 138/469 - loss 1.11215429 - samples/sec: 45.21 - lr: 0.100000\n",
      "2021-03-29 10:16:06,673 epoch 3 - iter 184/469 - loss 1.09024618 - samples/sec: 44.96 - lr: 0.100000\n",
      "2021-03-29 10:16:35,960 epoch 3 - iter 230/469 - loss 1.08782906 - samples/sec: 50.27 - lr: 0.100000\n",
      "2021-03-29 10:17:03,928 epoch 3 - iter 276/469 - loss 1.08136921 - samples/sec: 52.65 - lr: 0.100000\n",
      "2021-03-29 10:17:33,669 epoch 3 - iter 322/469 - loss 1.05855202 - samples/sec: 49.51 - lr: 0.100000\n",
      "2021-03-29 10:18:05,105 epoch 3 - iter 368/469 - loss 1.06377955 - samples/sec: 46.83 - lr: 0.100000\n",
      "2021-03-29 10:18:34,324 epoch 3 - iter 414/469 - loss 1.05628625 - samples/sec: 50.39 - lr: 0.100000\n",
      "2021-03-29 10:19:04,158 epoch 3 - iter 460/469 - loss 1.05462315 - samples/sec: 49.35 - lr: 0.100000\n",
      "2021-03-29 10:19:09,900 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:19:09,903 EPOCH 3 done: loss 1.0548 - lr 0.1000000\n",
      "2021-03-29 10:19:27,360 DEV : loss 0.601652204990387 - score 0.9234\n",
      "2021-03-29 10:19:27,639 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-29 10:19:34,517 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:20:03,472 epoch 4 - iter 46/469 - loss 0.90916251 - samples/sec: 50.86 - lr: 0.100000\n",
      "2021-03-29 10:20:33,034 epoch 4 - iter 92/469 - loss 0.90573167 - samples/sec: 49.80 - lr: 0.100000\n",
      "2021-03-29 10:21:03,739 epoch 4 - iter 138/469 - loss 0.90700697 - samples/sec: 47.95 - lr: 0.100000\n",
      "2021-03-29 10:21:37,420 epoch 4 - iter 184/469 - loss 0.89877791 - samples/sec: 43.72 - lr: 0.100000\n",
      "2021-03-29 10:22:08,995 epoch 4 - iter 230/469 - loss 0.90486854 - samples/sec: 46.63 - lr: 0.100000\n",
      "2021-03-29 10:22:39,676 epoch 4 - iter 276/469 - loss 0.90021600 - samples/sec: 47.99 - lr: 0.100000\n",
      "2021-03-29 10:23:11,299 epoch 4 - iter 322/469 - loss 0.90124734 - samples/sec: 46.56 - lr: 0.100000\n",
      "2021-03-29 10:23:41,542 epoch 4 - iter 368/469 - loss 0.90705192 - samples/sec: 48.69 - lr: 0.100000\n",
      "2021-03-29 10:24:12,102 epoch 4 - iter 414/469 - loss 0.89987937 - samples/sec: 48.17 - lr: 0.100000\n",
      "2021-03-29 10:24:43,842 epoch 4 - iter 460/469 - loss 0.90740493 - samples/sec: 46.39 - lr: 0.100000\n",
      "2021-03-29 10:24:49,479 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:24:49,481 EPOCH 4 done: loss 0.9059 - lr 0.1000000\n",
      "2021-03-29 10:25:08,229 DEV : loss 0.6013156771659851 - score 0.931\n",
      "2021-03-29 10:25:08,534 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-29 10:25:16,780 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:25:47,335 epoch 5 - iter 46/469 - loss 0.81400713 - samples/sec: 48.19 - lr: 0.100000\n",
      "2021-03-29 10:26:18,956 epoch 5 - iter 92/469 - loss 0.85452718 - samples/sec: 46.56 - lr: 0.100000\n",
      "2021-03-29 10:26:50,531 epoch 5 - iter 138/469 - loss 0.83297074 - samples/sec: 46.63 - lr: 0.100000\n",
      "2021-03-29 10:27:22,158 epoch 5 - iter 184/469 - loss 0.83289473 - samples/sec: 46.55 - lr: 0.100000\n",
      "2021-03-29 10:27:52,827 epoch 5 - iter 230/469 - loss 0.81266856 - samples/sec: 48.01 - lr: 0.100000\n",
      "2021-03-29 10:28:25,585 epoch 5 - iter 276/469 - loss 0.83656520 - samples/sec: 44.94 - lr: 0.100000\n",
      "2021-03-29 10:28:57,230 epoch 5 - iter 322/469 - loss 0.82267475 - samples/sec: 46.53 - lr: 0.100000\n",
      "2021-03-29 10:29:29,015 epoch 5 - iter 368/469 - loss 0.83438288 - samples/sec: 46.32 - lr: 0.100000\n",
      "2021-03-29 10:29:58,613 epoch 5 - iter 414/469 - loss 0.83256105 - samples/sec: 49.74 - lr: 0.100000\n",
      "2021-03-29 10:30:29,751 epoch 5 - iter 460/469 - loss 0.82714328 - samples/sec: 47.28 - lr: 0.100000\n",
      "2021-03-29 10:30:35,520 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:30:35,522 EPOCH 5 done: loss 0.8264 - lr 0.1000000\n",
      "2021-03-29 10:30:54,134 DEV : loss 0.5404952764511108 - score 0.9347\n",
      "2021-03-29 10:30:54,424 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-29 10:31:00,505 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:31:32,079 epoch 6 - iter 46/469 - loss 0.74171695 - samples/sec: 46.64 - lr: 0.100000\n",
      "2021-03-29 10:32:01,476 epoch 6 - iter 92/469 - loss 0.75301053 - samples/sec: 50.08 - lr: 0.100000\n",
      "2021-03-29 10:32:32,584 epoch 6 - iter 138/469 - loss 0.74871996 - samples/sec: 47.33 - lr: 0.100000\n",
      "2021-03-29 10:33:02,771 epoch 6 - iter 184/469 - loss 0.73629346 - samples/sec: 48.78 - lr: 0.100000\n",
      "2021-03-29 10:33:34,658 epoch 6 - iter 230/469 - loss 0.74075086 - samples/sec: 46.17 - lr: 0.100000\n",
      "2021-03-29 10:34:09,937 epoch 6 - iter 276/469 - loss 0.73898804 - samples/sec: 41.73 - lr: 0.100000\n",
      "2021-03-29 10:34:36,936 epoch 6 - iter 322/469 - loss 0.74110239 - samples/sec: 54.53 - lr: 0.100000\n",
      "2021-03-29 10:35:02,223 epoch 6 - iter 368/469 - loss 0.74282789 - samples/sec: 58.22 - lr: 0.100000\n",
      "2021-03-29 10:35:28,800 epoch 6 - iter 414/469 - loss 0.74399675 - samples/sec: 55.40 - lr: 0.100000\n",
      "2021-03-29 10:35:54,208 epoch 6 - iter 460/469 - loss 0.74265099 - samples/sec: 57.95 - lr: 0.100000\n",
      "2021-03-29 10:35:59,010 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:35:59,011 EPOCH 6 done: loss 0.7453 - lr 0.1000000\n",
      "2021-03-29 10:36:14,378 DEV : loss 0.5448549389839172 - score 0.9343\n",
      "2021-03-29 10:36:14,684 BAD EPOCHS (no improvement): 1\n",
      "2021-03-29 10:36:14,685 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:36:42,133 epoch 7 - iter 46/469 - loss 0.70209183 - samples/sec: 53.65 - lr: 0.100000\n",
      "2021-03-29 10:37:07,771 epoch 7 - iter 92/469 - loss 0.71219647 - samples/sec: 57.42 - lr: 0.100000\n",
      "2021-03-29 10:37:34,513 epoch 7 - iter 138/469 - loss 0.71502903 - samples/sec: 55.05 - lr: 0.100000\n",
      "2021-03-29 10:37:59,680 epoch 7 - iter 184/469 - loss 0.70788359 - samples/sec: 58.50 - lr: 0.100000\n",
      "2021-03-29 10:38:25,089 epoch 7 - iter 230/469 - loss 0.70408239 - samples/sec: 57.94 - lr: 0.100000\n",
      "2021-03-29 10:38:52,135 epoch 7 - iter 276/469 - loss 0.69567892 - samples/sec: 54.43 - lr: 0.100000\n",
      "2021-03-29 10:39:19,766 epoch 7 - iter 322/469 - loss 0.70825729 - samples/sec: 53.28 - lr: 0.100000\n",
      "2021-03-29 10:39:44,989 epoch 7 - iter 368/469 - loss 0.70051734 - samples/sec: 58.37 - lr: 0.100000\n",
      "2021-03-29 10:40:10,769 epoch 7 - iter 414/469 - loss 0.70453995 - samples/sec: 57.11 - lr: 0.100000\n",
      "2021-03-29 10:40:36,010 epoch 7 - iter 460/469 - loss 0.70265634 - samples/sec: 58.33 - lr: 0.100000\n",
      "2021-03-29 10:40:40,655 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:40:40,658 EPOCH 7 done: loss 0.7000 - lr 0.1000000\n",
      "2021-03-29 10:40:56,670 DEV : loss 0.5235238075256348 - score 0.9318\n",
      "2021-03-29 10:40:56,885 BAD EPOCHS (no improvement): 2\n",
      "2021-03-29 10:40:56,886 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:41:23,006 epoch 8 - iter 46/469 - loss 0.61713644 - samples/sec: 56.36 - lr: 0.100000\n",
      "2021-03-29 10:41:48,691 epoch 8 - iter 92/469 - loss 0.63742242 - samples/sec: 57.32 - lr: 0.100000\n",
      "2021-03-29 10:42:14,175 epoch 8 - iter 138/469 - loss 0.65072351 - samples/sec: 57.77 - lr: 0.100000\n",
      "2021-03-29 10:42:39,562 epoch 8 - iter 184/469 - loss 0.65759503 - samples/sec: 58.00 - lr: 0.100000\n",
      "2021-03-29 10:43:04,443 epoch 8 - iter 230/469 - loss 0.65541597 - samples/sec: 59.17 - lr: 0.100000\n",
      "2021-03-29 10:43:30,393 epoch 8 - iter 276/469 - loss 0.63945842 - samples/sec: 56.74 - lr: 0.100000\n",
      "2021-03-29 10:43:55,098 epoch 8 - iter 322/469 - loss 0.64489789 - samples/sec: 59.60 - lr: 0.100000\n",
      "2021-03-29 10:44:22,683 epoch 8 - iter 368/469 - loss 0.64413053 - samples/sec: 53.38 - lr: 0.100000\n",
      "2021-03-29 10:44:48,531 epoch 8 - iter 414/469 - loss 0.64991039 - samples/sec: 56.95 - lr: 0.100000\n",
      "2021-03-29 10:45:14,017 epoch 8 - iter 460/469 - loss 0.65236401 - samples/sec: 57.77 - lr: 0.100000\n",
      "2021-03-29 10:45:19,571 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:45:19,572 EPOCH 8 done: loss 0.6556 - lr 0.1000000\n",
      "2021-03-29 10:45:34,783 DEV : loss 0.5005514621734619 - score 0.9364\n",
      "2021-03-29 10:45:35,049 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-29 10:45:40,128 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:46:06,394 epoch 9 - iter 46/469 - loss 0.61749153 - samples/sec: 56.06 - lr: 0.100000\n",
      "2021-03-29 10:46:31,389 epoch 9 - iter 92/469 - loss 0.62532985 - samples/sec: 58.91 - lr: 0.100000\n",
      "2021-03-29 10:46:56,892 epoch 9 - iter 138/469 - loss 0.63343238 - samples/sec: 57.73 - lr: 0.100000\n",
      "2021-03-29 10:47:23,287 epoch 9 - iter 184/469 - loss 0.63234187 - samples/sec: 55.78 - lr: 0.100000\n",
      "2021-03-29 10:47:49,831 epoch 9 - iter 230/469 - loss 0.61244981 - samples/sec: 55.47 - lr: 0.100000\n",
      "2021-03-29 10:48:15,257 epoch 9 - iter 276/469 - loss 0.61694099 - samples/sec: 57.90 - lr: 0.100000\n",
      "2021-03-29 10:48:40,504 epoch 9 - iter 322/469 - loss 0.60842829 - samples/sec: 58.31 - lr: 0.100000\n",
      "2021-03-29 10:49:06,115 epoch 9 - iter 368/469 - loss 0.61987256 - samples/sec: 57.49 - lr: 0.100000\n",
      "2021-03-29 10:49:35,393 epoch 9 - iter 414/469 - loss 0.61619297 - samples/sec: 50.29 - lr: 0.100000\n",
      "2021-03-29 10:50:01,430 epoch 9 - iter 460/469 - loss 0.61318455 - samples/sec: 56.55 - lr: 0.100000\n",
      "2021-03-29 10:50:06,152 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:50:06,153 EPOCH 9 done: loss 0.6131 - lr 0.1000000\n",
      "2021-03-29 10:50:21,381 DEV : loss 0.473529189825058 - score 0.9441\n",
      "2021-03-29 10:50:21,636 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-29 10:50:26,974 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:50:53,722 epoch 10 - iter 46/469 - loss 0.54570538 - samples/sec: 55.05 - lr: 0.100000\n",
      "2021-03-29 10:51:18,778 epoch 10 - iter 92/469 - loss 0.55970492 - samples/sec: 58.76 - lr: 0.100000\n",
      "2021-03-29 10:51:45,570 epoch 10 - iter 138/469 - loss 0.57979857 - samples/sec: 54.95 - lr: 0.100000\n",
      "2021-03-29 10:52:12,721 epoch 10 - iter 184/469 - loss 0.59123198 - samples/sec: 54.23 - lr: 0.100000\n",
      "2021-03-29 10:52:37,555 epoch 10 - iter 230/469 - loss 0.57175152 - samples/sec: 59.29 - lr: 0.100000\n",
      "2021-03-29 10:53:03,301 epoch 10 - iter 276/469 - loss 0.57922256 - samples/sec: 57.20 - lr: 0.100000\n",
      "2021-03-29 10:53:28,019 epoch 10 - iter 322/469 - loss 0.58113724 - samples/sec: 59.56 - lr: 0.100000\n",
      "2021-03-29 10:53:54,878 epoch 10 - iter 368/469 - loss 0.58859319 - samples/sec: 54.81 - lr: 0.100000\n",
      "2021-03-29 10:54:20,827 epoch 10 - iter 414/469 - loss 0.59264172 - samples/sec: 56.74 - lr: 0.100000\n",
      "2021-03-29 10:54:49,226 epoch 10 - iter 460/469 - loss 0.59065410 - samples/sec: 51.84 - lr: 0.100000\n",
      "2021-03-29 10:54:54,060 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:54:54,062 EPOCH 10 done: loss 0.5913 - lr 0.1000000\n",
      "2021-03-29 10:55:08,963 DEV : loss 0.5186625719070435 - score 0.9386\n",
      "2021-03-29 10:55:09,222 BAD EPOCHS (no improvement): 1\n",
      "2021-03-29 10:55:09,225 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:55:35,686 epoch 11 - iter 46/469 - loss 0.52716560 - samples/sec: 55.65 - lr: 0.100000\n",
      "2021-03-29 10:56:00,682 epoch 11 - iter 92/469 - loss 0.57051440 - samples/sec: 58.91 - lr: 0.100000\n",
      "2021-03-29 10:56:25,963 epoch 11 - iter 138/469 - loss 0.56296186 - samples/sec: 58.24 - lr: 0.100000\n",
      "2021-03-29 10:56:53,726 epoch 11 - iter 184/469 - loss 0.57349170 - samples/sec: 53.03 - lr: 0.100000\n",
      "2021-03-29 10:57:19,821 epoch 11 - iter 230/469 - loss 0.56578087 - samples/sec: 56.42 - lr: 0.100000\n",
      "2021-03-29 10:57:46,356 epoch 11 - iter 276/469 - loss 0.56562875 - samples/sec: 55.49 - lr: 0.100000\n",
      "2021-03-29 10:58:11,273 epoch 11 - iter 322/469 - loss 0.56007105 - samples/sec: 59.09 - lr: 0.100000\n",
      "2021-03-29 10:58:36,461 epoch 11 - iter 368/469 - loss 0.56364482 - samples/sec: 58.45 - lr: 0.100000\n",
      "2021-03-29 10:59:02,734 epoch 11 - iter 414/469 - loss 0.55915710 - samples/sec: 56.03 - lr: 0.100000\n",
      "2021-03-29 10:59:28,286 epoch 11 - iter 460/469 - loss 0.55961348 - samples/sec: 57.62 - lr: 0.100000\n",
      "2021-03-29 10:59:33,307 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 10:59:33,310 EPOCH 11 done: loss 0.5592 - lr 0.1000000\n",
      "2021-03-29 10:59:49,353 DEV : loss 0.4846130907535553 - score 0.946\n",
      "2021-03-29 10:59:49,661 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-29 10:59:55,453 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:00:20,672 epoch 12 - iter 46/469 - loss 0.52105713 - samples/sec: 58.39 - lr: 0.100000\n",
      "2021-03-29 11:00:47,732 epoch 12 - iter 92/469 - loss 0.56846062 - samples/sec: 54.41 - lr: 0.100000\n",
      "2021-03-29 11:01:13,481 epoch 12 - iter 138/469 - loss 0.55917896 - samples/sec: 57.18 - lr: 0.100000\n",
      "2021-03-29 11:01:44,010 epoch 12 - iter 184/469 - loss 0.54595753 - samples/sec: 48.22 - lr: 0.100000\n",
      "2021-03-29 11:02:10,653 epoch 12 - iter 230/469 - loss 0.54399526 - samples/sec: 55.26 - lr: 0.100000\n",
      "2021-03-29 11:02:35,337 epoch 12 - iter 276/469 - loss 0.54199411 - samples/sec: 59.65 - lr: 0.100000\n",
      "2021-03-29 11:03:01,817 epoch 12 - iter 322/469 - loss 0.54389158 - samples/sec: 55.60 - lr: 0.100000\n",
      "2021-03-29 11:03:28,149 epoch 12 - iter 368/469 - loss 0.54168344 - samples/sec: 55.92 - lr: 0.100000\n",
      "2021-03-29 11:03:54,931 epoch 12 - iter 414/469 - loss 0.54477568 - samples/sec: 54.97 - lr: 0.100000\n",
      "2021-03-29 11:04:21,619 epoch 12 - iter 460/469 - loss 0.54181913 - samples/sec: 55.16 - lr: 0.100000\n",
      "2021-03-29 11:04:26,128 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:04:26,129 EPOCH 12 done: loss 0.5420 - lr 0.1000000\n",
      "2021-03-29 11:04:41,095 DEV : loss 0.4922506809234619 - score 0.945\n",
      "2021-03-29 11:04:41,350 BAD EPOCHS (no improvement): 1\n",
      "2021-03-29 11:04:41,352 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:05:09,336 epoch 13 - iter 46/469 - loss 0.53000031 - samples/sec: 52.61 - lr: 0.100000\n",
      "2021-03-29 11:05:35,057 epoch 13 - iter 92/469 - loss 0.51336697 - samples/sec: 57.24 - lr: 0.100000\n",
      "2021-03-29 11:06:00,812 epoch 13 - iter 138/469 - loss 0.51452370 - samples/sec: 57.16 - lr: 0.100000\n",
      "2021-03-29 11:06:30,237 epoch 13 - iter 184/469 - loss 0.52384614 - samples/sec: 50.03 - lr: 0.100000\n",
      "2021-03-29 11:06:55,975 epoch 13 - iter 230/469 - loss 0.51543885 - samples/sec: 57.20 - lr: 0.100000\n",
      "2021-03-29 11:07:22,052 epoch 13 - iter 276/469 - loss 0.51509216 - samples/sec: 56.46 - lr: 0.100000\n",
      "2021-03-29 11:07:47,701 epoch 13 - iter 322/469 - loss 0.51583377 - samples/sec: 57.39 - lr: 0.100000\n",
      "2021-03-29 11:08:14,670 epoch 13 - iter 368/469 - loss 0.51608064 - samples/sec: 54.59 - lr: 0.100000\n",
      "2021-03-29 11:08:42,139 epoch 13 - iter 414/469 - loss 0.51306092 - samples/sec: 53.60 - lr: 0.100000\n",
      "2021-03-29 11:09:08,368 epoch 13 - iter 460/469 - loss 0.51452133 - samples/sec: 56.13 - lr: 0.100000\n",
      "2021-03-29 11:09:13,343 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:09:13,345 EPOCH 13 done: loss 0.5153 - lr 0.1000000\n",
      "2021-03-29 11:09:28,645 DEV : loss 0.4766833782196045 - score 0.9432\n",
      "2021-03-29 11:09:28,902 BAD EPOCHS (no improvement): 2\n",
      "2021-03-29 11:09:28,904 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:09:56,598 epoch 14 - iter 46/469 - loss 0.44343199 - samples/sec: 53.17 - lr: 0.100000\n",
      "2021-03-29 11:10:26,071 epoch 14 - iter 92/469 - loss 0.44900537 - samples/sec: 49.96 - lr: 0.100000\n",
      "2021-03-29 11:10:52,699 epoch 14 - iter 138/469 - loss 0.45003629 - samples/sec: 55.29 - lr: 0.100000\n",
      "2021-03-29 11:11:19,014 epoch 14 - iter 184/469 - loss 0.45455190 - samples/sec: 55.94 - lr: 0.100000\n",
      "2021-03-29 11:11:44,975 epoch 14 - iter 230/469 - loss 0.46515210 - samples/sec: 56.71 - lr: 0.100000\n",
      "2021-03-29 11:12:10,546 epoch 14 - iter 276/469 - loss 0.46814449 - samples/sec: 57.58 - lr: 0.100000\n",
      "2021-03-29 11:12:35,887 epoch 14 - iter 322/469 - loss 0.47658250 - samples/sec: 58.10 - lr: 0.100000\n",
      "2021-03-29 11:13:01,056 epoch 14 - iter 368/469 - loss 0.48169954 - samples/sec: 58.49 - lr: 0.100000\n",
      "2021-03-29 11:13:27,422 epoch 14 - iter 414/469 - loss 0.48980800 - samples/sec: 55.84 - lr: 0.100000\n",
      "2021-03-29 11:13:53,193 epoch 14 - iter 460/469 - loss 0.49456540 - samples/sec: 57.13 - lr: 0.100000\n",
      "2021-03-29 11:13:57,852 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:13:57,853 EPOCH 14 done: loss 0.4932 - lr 0.1000000\n",
      "2021-03-29 11:14:13,023 DEV : loss 0.5163813233375549 - score 0.9442\n",
      "2021-03-29 11:14:13,294 BAD EPOCHS (no improvement): 3\n",
      "2021-03-29 11:14:13,296 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:14:39,886 epoch 15 - iter 46/469 - loss 0.48199867 - samples/sec: 55.38 - lr: 0.100000\n",
      "2021-03-29 11:15:05,812 epoch 15 - iter 92/469 - loss 0.48236804 - samples/sec: 56.78 - lr: 0.100000\n",
      "2021-03-29 11:15:34,160 epoch 15 - iter 138/469 - loss 0.47665447 - samples/sec: 51.94 - lr: 0.100000\n",
      "2021-03-29 11:16:00,893 epoch 15 - iter 184/469 - loss 0.46870191 - samples/sec: 55.08 - lr: 0.100000\n",
      "2021-03-29 11:16:25,760 epoch 15 - iter 230/469 - loss 0.46255098 - samples/sec: 59.22 - lr: 0.100000\n",
      "2021-03-29 11:16:51,099 epoch 15 - iter 276/469 - loss 0.46003190 - samples/sec: 58.10 - lr: 0.100000\n",
      "2021-03-29 11:17:16,683 epoch 15 - iter 322/469 - loss 0.46796979 - samples/sec: 57.55 - lr: 0.100000\n",
      "2021-03-29 11:17:41,050 epoch 15 - iter 368/469 - loss 0.46405265 - samples/sec: 60.42 - lr: 0.100000\n",
      "2021-03-29 11:18:08,167 epoch 15 - iter 414/469 - loss 0.46483660 - samples/sec: 54.29 - lr: 0.100000\n",
      "2021-03-29 11:18:34,666 epoch 15 - iter 460/469 - loss 0.46439363 - samples/sec: 55.57 - lr: 0.100000\n",
      "2021-03-29 11:18:39,510 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:18:39,511 EPOCH 15 done: loss 0.4690 - lr 0.1000000\n",
      "2021-03-29 11:18:54,586 DEV : loss 0.4879426658153534 - score 0.9415\n",
      "Epoch    15: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2021-03-29 11:18:54,864 BAD EPOCHS (no improvement): 4\n",
      "2021-03-29 11:18:54,867 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:19:21,816 epoch 16 - iter 46/469 - loss 0.46771197 - samples/sec: 54.64 - lr: 0.050000\n",
      "2021-03-29 11:19:47,629 epoch 16 - iter 92/469 - loss 0.46342788 - samples/sec: 57.04 - lr: 0.050000\n",
      "2021-03-29 11:20:12,971 epoch 16 - iter 138/469 - loss 0.46234437 - samples/sec: 58.09 - lr: 0.050000\n",
      "2021-03-29 11:20:38,815 epoch 16 - iter 184/469 - loss 0.45558161 - samples/sec: 56.97 - lr: 0.050000\n",
      "2021-03-29 11:21:08,003 epoch 16 - iter 230/469 - loss 0.43944337 - samples/sec: 50.44 - lr: 0.050000\n",
      "2021-03-29 11:21:33,927 epoch 16 - iter 276/469 - loss 0.43851919 - samples/sec: 56.79 - lr: 0.050000\n",
      "2021-03-29 11:22:00,029 epoch 16 - iter 322/469 - loss 0.43020434 - samples/sec: 56.40 - lr: 0.050000\n",
      "2021-03-29 11:22:24,242 epoch 16 - iter 368/469 - loss 0.42743509 - samples/sec: 60.81 - lr: 0.050000\n",
      "2021-03-29 11:22:50,072 epoch 16 - iter 414/469 - loss 0.42917787 - samples/sec: 57.00 - lr: 0.050000\n",
      "2021-03-29 11:23:14,362 epoch 16 - iter 460/469 - loss 0.42928738 - samples/sec: 60.60 - lr: 0.050000\n",
      "2021-03-29 11:23:19,493 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:23:19,494 EPOCH 16 done: loss 0.4337 - lr 0.0500000\n",
      "2021-03-29 11:23:35,926 DEV : loss 0.45182764530181885 - score 0.9461\n",
      "2021-03-29 11:23:36,150 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-29 11:23:40,938 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:24:06,454 epoch 17 - iter 46/469 - loss 0.43562665 - samples/sec: 57.72 - lr: 0.050000\n",
      "2021-03-29 11:24:31,911 epoch 17 - iter 92/469 - loss 0.42091511 - samples/sec: 57.83 - lr: 0.050000\n",
      "2021-03-29 11:24:57,892 epoch 17 - iter 138/469 - loss 0.41008888 - samples/sec: 56.67 - lr: 0.050000\n",
      "2021-03-29 11:25:23,774 epoch 17 - iter 184/469 - loss 0.40586038 - samples/sec: 56.88 - lr: 0.050000\n",
      "2021-03-29 11:25:49,588 epoch 17 - iter 230/469 - loss 0.41327674 - samples/sec: 57.04 - lr: 0.050000\n",
      "2021-03-29 11:26:17,919 epoch 17 - iter 276/469 - loss 0.40593124 - samples/sec: 51.97 - lr: 0.050000\n",
      "2021-03-29 11:26:44,752 epoch 17 - iter 322/469 - loss 0.40550845 - samples/sec: 54.86 - lr: 0.050000\n",
      "2021-03-29 11:27:11,023 epoch 17 - iter 368/469 - loss 0.40319020 - samples/sec: 56.04 - lr: 0.050000\n",
      "2021-03-29 11:27:35,716 epoch 17 - iter 414/469 - loss 0.40422686 - samples/sec: 59.62 - lr: 0.050000\n",
      "2021-03-29 11:28:02,515 epoch 17 - iter 460/469 - loss 0.40488101 - samples/sec: 54.94 - lr: 0.050000\n",
      "2021-03-29 11:28:07,543 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:28:07,545 EPOCH 17 done: loss 0.4094 - lr 0.0500000\n",
      "2021-03-29 11:28:22,592 DEV : loss 0.4509797990322113 - score 0.947\n",
      "2021-03-29 11:28:22,869 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-29 11:28:27,516 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:28:52,599 epoch 18 - iter 46/469 - loss 0.37525009 - samples/sec: 58.71 - lr: 0.050000\n",
      "2021-03-29 11:29:18,745 epoch 18 - iter 92/469 - loss 0.37044426 - samples/sec: 56.31 - lr: 0.050000\n",
      "2021-03-29 11:29:45,146 epoch 18 - iter 138/469 - loss 0.38006916 - samples/sec: 55.77 - lr: 0.050000\n",
      "2021-03-29 11:30:10,505 epoch 18 - iter 184/469 - loss 0.37998072 - samples/sec: 58.06 - lr: 0.050000\n",
      "2021-03-29 11:30:36,269 epoch 18 - iter 230/469 - loss 0.36908600 - samples/sec: 57.15 - lr: 0.050000\n",
      "2021-03-29 11:31:02,910 epoch 18 - iter 276/469 - loss 0.37673631 - samples/sec: 55.27 - lr: 0.050000\n",
      "2021-03-29 11:31:31,800 epoch 18 - iter 322/469 - loss 0.38512482 - samples/sec: 50.96 - lr: 0.050000\n",
      "2021-03-29 11:31:58,184 epoch 18 - iter 368/469 - loss 0.39275297 - samples/sec: 55.80 - lr: 0.050000\n",
      "2021-03-29 11:32:23,544 epoch 18 - iter 414/469 - loss 0.39607015 - samples/sec: 58.06 - lr: 0.050000\n",
      "2021-03-29 11:32:48,885 epoch 18 - iter 460/469 - loss 0.39077898 - samples/sec: 58.10 - lr: 0.050000\n",
      "2021-03-29 11:32:53,572 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:32:53,574 EPOCH 18 done: loss 0.3917 - lr 0.0500000\n",
      "2021-03-29 11:33:08,760 DEV : loss 0.4620245099067688 - score 0.9484\n",
      "2021-03-29 11:33:09,003 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-29 11:33:13,720 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:33:39,200 epoch 19 - iter 46/469 - loss 0.40040195 - samples/sec: 57.78 - lr: 0.050000\n",
      "2021-03-29 11:34:05,217 epoch 19 - iter 92/469 - loss 0.36767705 - samples/sec: 56.59 - lr: 0.050000\n",
      "2021-03-29 11:34:31,215 epoch 19 - iter 138/469 - loss 0.36320002 - samples/sec: 56.64 - lr: 0.050000\n",
      "2021-03-29 11:34:57,549 epoch 19 - iter 184/469 - loss 0.35911926 - samples/sec: 55.90 - lr: 0.050000\n",
      "2021-03-29 11:35:23,593 epoch 19 - iter 230/469 - loss 0.36427903 - samples/sec: 56.53 - lr: 0.050000\n",
      "2021-03-29 11:35:53,568 epoch 19 - iter 276/469 - loss 0.36347099 - samples/sec: 49.11 - lr: 0.050000\n",
      "2021-03-29 11:36:23,097 epoch 19 - iter 322/469 - loss 0.36380092 - samples/sec: 49.86 - lr: 0.050000\n",
      "2021-03-29 11:36:53,839 epoch 19 - iter 368/469 - loss 0.36109560 - samples/sec: 47.90 - lr: 0.050000\n",
      "2021-03-29 11:37:23,813 epoch 19 - iter 414/469 - loss 0.36366504 - samples/sec: 49.12 - lr: 0.050000\n",
      "2021-03-29 11:37:54,040 epoch 19 - iter 460/469 - loss 0.36806372 - samples/sec: 48.71 - lr: 0.050000\n",
      "2021-03-29 11:37:59,324 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:37:59,326 EPOCH 19 done: loss 0.3701 - lr 0.0500000\n",
      "2021-03-29 11:38:16,624 DEV : loss 0.4741843342781067 - score 0.9515\n",
      "2021-03-29 11:38:16,907 BAD EPOCHS (no improvement): 0\n",
      "saving best model\n",
      "2021-03-29 11:38:21,926 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:38:50,789 epoch 20 - iter 46/469 - loss 0.36716623 - samples/sec: 51.01 - lr: 0.050000\n",
      "2021-03-29 11:39:19,151 epoch 20 - iter 92/469 - loss 0.35980180 - samples/sec: 51.91 - lr: 0.050000\n",
      "2021-03-29 11:39:47,972 epoch 20 - iter 138/469 - loss 0.36638615 - samples/sec: 51.08 - lr: 0.050000\n",
      "2021-03-29 11:40:17,806 epoch 20 - iter 184/469 - loss 0.36384680 - samples/sec: 49.35 - lr: 0.050000\n",
      "2021-03-29 11:40:48,270 epoch 20 - iter 230/469 - loss 0.36654822 - samples/sec: 48.32 - lr: 0.050000\n",
      "2021-03-29 11:41:17,091 epoch 20 - iter 276/469 - loss 0.36718420 - samples/sec: 51.08 - lr: 0.050000\n",
      "2021-03-29 11:41:46,069 epoch 20 - iter 322/469 - loss 0.36483276 - samples/sec: 50.81 - lr: 0.050000\n",
      "2021-03-29 11:42:16,040 epoch 20 - iter 368/469 - loss 0.35970017 - samples/sec: 49.12 - lr: 0.050000\n",
      "2021-03-29 11:42:46,443 epoch 20 - iter 414/469 - loss 0.36414003 - samples/sec: 48.43 - lr: 0.050000\n",
      "2021-03-29 11:43:15,876 epoch 20 - iter 460/469 - loss 0.36565753 - samples/sec: 50.03 - lr: 0.050000\n",
      "2021-03-29 11:43:20,483 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:43:20,485 EPOCH 20 done: loss 0.3634 - lr 0.0500000\n",
      "2021-03-29 11:43:37,591 DEV : loss 0.4649021327495575 - score 0.948\n",
      "2021-03-29 11:43:37,871 BAD EPOCHS (no improvement): 1\n",
      "2021-03-29 11:43:37,873 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:44:07,938 epoch 21 - iter 46/469 - loss 0.39041007 - samples/sec: 48.97 - lr: 0.050000\n",
      "2021-03-29 11:44:35,256 epoch 21 - iter 92/469 - loss 0.36560699 - samples/sec: 53.89 - lr: 0.050000\n",
      "2021-03-29 11:45:04,635 epoch 21 - iter 138/469 - loss 0.36024654 - samples/sec: 50.12 - lr: 0.050000\n",
      "2021-03-29 11:45:34,117 epoch 21 - iter 184/469 - loss 0.35988315 - samples/sec: 49.93 - lr: 0.050000\n",
      "2021-03-29 11:46:03,939 epoch 21 - iter 230/469 - loss 0.36375207 - samples/sec: 49.37 - lr: 0.050000\n",
      "2021-03-29 11:46:31,504 epoch 21 - iter 276/469 - loss 0.36521631 - samples/sec: 53.41 - lr: 0.050000\n",
      "2021-03-29 11:46:58,710 epoch 21 - iter 322/469 - loss 0.36752198 - samples/sec: 54.11 - lr: 0.050000\n",
      "2021-03-29 11:47:26,852 epoch 21 - iter 368/469 - loss 0.36687708 - samples/sec: 52.31 - lr: 0.050000\n",
      "2021-03-29 11:47:53,732 epoch 21 - iter 414/469 - loss 0.36531860 - samples/sec: 54.77 - lr: 0.050000\n",
      "2021-03-29 11:48:19,444 epoch 21 - iter 460/469 - loss 0.36240540 - samples/sec: 57.26 - lr: 0.050000\n",
      "2021-03-29 11:48:24,094 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:48:24,097 EPOCH 21 done: loss 0.3633 - lr 0.0500000\n",
      "2021-03-29 11:48:39,365 DEV : loss 0.4663154184818268 - score 0.9494\n",
      "2021-03-29 11:48:39,630 BAD EPOCHS (no improvement): 2\n",
      "2021-03-29 11:48:39,633 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:49:06,891 epoch 22 - iter 46/469 - loss 0.37268298 - samples/sec: 54.02 - lr: 0.050000\n",
      "2021-03-29 11:49:33,265 epoch 22 - iter 92/469 - loss 0.36858694 - samples/sec: 55.82 - lr: 0.050000\n",
      "2021-03-29 11:50:00,132 epoch 22 - iter 138/469 - loss 0.37193635 - samples/sec: 54.80 - lr: 0.050000\n",
      "2021-03-29 11:50:25,107 epoch 22 - iter 184/469 - loss 0.36666859 - samples/sec: 58.95 - lr: 0.050000\n",
      "2021-03-29 11:50:51,118 epoch 22 - iter 230/469 - loss 0.35774153 - samples/sec: 56.61 - lr: 0.050000\n",
      "2021-03-29 11:51:16,733 epoch 22 - iter 276/469 - loss 0.34820637 - samples/sec: 57.48 - lr: 0.050000\n",
      "2021-03-29 11:51:41,938 epoch 22 - iter 322/469 - loss 0.34080466 - samples/sec: 58.41 - lr: 0.050000\n",
      "2021-03-29 11:52:07,928 epoch 22 - iter 368/469 - loss 0.34079921 - samples/sec: 56.65 - lr: 0.050000\n",
      "2021-03-29 11:52:35,750 epoch 22 - iter 414/469 - loss 0.34357434 - samples/sec: 52.92 - lr: 0.050000\n",
      "2021-03-29 11:53:01,959 epoch 22 - iter 460/469 - loss 0.34867784 - samples/sec: 56.17 - lr: 0.050000\n",
      "2021-03-29 11:53:06,734 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:53:06,736 EPOCH 22 done: loss 0.3473 - lr 0.0500000\n",
      "2021-03-29 11:53:22,237 DEV : loss 0.4798979163169861 - score 0.9473\n",
      "2021-03-29 11:53:22,504 BAD EPOCHS (no improvement): 3\n",
      "2021-03-29 11:53:22,506 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:53:49,793 epoch 23 - iter 46/469 - loss 0.37427553 - samples/sec: 53.96 - lr: 0.050000\n",
      "2021-03-29 11:54:15,448 epoch 23 - iter 92/469 - loss 0.34277330 - samples/sec: 57.38 - lr: 0.050000\n",
      "2021-03-29 11:54:40,953 epoch 23 - iter 138/469 - loss 0.34335088 - samples/sec: 57.72 - lr: 0.050000\n",
      "2021-03-29 11:55:07,255 epoch 23 - iter 184/469 - loss 0.32850952 - samples/sec: 55.98 - lr: 0.050000\n",
      "2021-03-29 11:55:32,661 epoch 23 - iter 230/469 - loss 0.32658422 - samples/sec: 57.95 - lr: 0.050000\n",
      "2021-03-29 11:55:59,725 epoch 23 - iter 276/469 - loss 0.32865720 - samples/sec: 54.40 - lr: 0.050000\n",
      "2021-03-29 11:56:24,215 epoch 23 - iter 322/469 - loss 0.33053001 - samples/sec: 60.11 - lr: 0.050000\n",
      "2021-03-29 11:56:50,096 epoch 23 - iter 368/469 - loss 0.33482511 - samples/sec: 56.88 - lr: 0.050000\n",
      "2021-03-29 11:57:16,280 epoch 23 - iter 414/469 - loss 0.33646956 - samples/sec: 56.22 - lr: 0.050000\n",
      "2021-03-29 11:57:44,400 epoch 23 - iter 460/469 - loss 0.33476684 - samples/sec: 52.36 - lr: 0.050000\n",
      "2021-03-29 11:57:49,192 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:57:49,194 EPOCH 23 done: loss 0.3349 - lr 0.0500000\n",
      "2021-03-29 11:58:04,444 DEV : loss 0.4801459312438965 - score 0.9479\n",
      "Epoch    23: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2021-03-29 11:58:04,694 BAD EPOCHS (no improvement): 4\n",
      "2021-03-29 11:58:04,696 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 11:58:30,701 epoch 24 - iter 46/469 - loss 0.34948997 - samples/sec: 56.62 - lr: 0.025000\n",
      "2021-03-29 11:58:55,678 epoch 24 - iter 92/469 - loss 0.34061349 - samples/sec: 58.95 - lr: 0.025000\n",
      "2021-03-29 11:59:21,358 epoch 24 - iter 138/469 - loss 0.33154388 - samples/sec: 57.33 - lr: 0.025000\n",
      "2021-03-29 11:59:48,113 epoch 24 - iter 184/469 - loss 0.32698103 - samples/sec: 55.03 - lr: 0.025000\n",
      "2021-03-29 12:00:13,968 epoch 24 - iter 230/469 - loss 0.32298874 - samples/sec: 56.94 - lr: 0.025000\n",
      "2021-03-29 12:00:40,554 epoch 24 - iter 276/469 - loss 0.32349168 - samples/sec: 55.38 - lr: 0.025000\n",
      "2021-03-29 12:01:05,736 epoch 24 - iter 322/469 - loss 0.32492816 - samples/sec: 58.47 - lr: 0.025000\n",
      "2021-03-29 12:01:29,802 epoch 24 - iter 368/469 - loss 0.32222460 - samples/sec: 61.18 - lr: 0.025000\n",
      "2021-03-29 12:01:55,250 epoch 24 - iter 414/469 - loss 0.32193233 - samples/sec: 57.85 - lr: 0.025000\n",
      "2021-03-29 12:02:21,033 epoch 24 - iter 460/469 - loss 0.32209867 - samples/sec: 57.10 - lr: 0.025000\n",
      "2021-03-29 12:02:25,635 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:02:25,638 EPOCH 24 done: loss 0.3216 - lr 0.0250000\n",
      "2021-03-29 12:02:40,695 DEV : loss 0.4897935390472412 - score 0.9488\n",
      "2021-03-29 12:02:40,972 BAD EPOCHS (no improvement): 1\n",
      "2021-03-29 12:02:40,975 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:03:08,963 epoch 25 - iter 46/469 - loss 0.35814403 - samples/sec: 52.61 - lr: 0.025000\n",
      "2021-03-29 12:03:34,749 epoch 25 - iter 92/469 - loss 0.31853551 - samples/sec: 57.10 - lr: 0.025000\n",
      "2021-03-29 12:04:01,384 epoch 25 - iter 138/469 - loss 0.31045614 - samples/sec: 55.28 - lr: 0.025000\n",
      "2021-03-29 12:04:26,645 epoch 25 - iter 184/469 - loss 0.30646148 - samples/sec: 58.28 - lr: 0.025000\n",
      "2021-03-29 12:04:52,390 epoch 25 - iter 230/469 - loss 0.30539465 - samples/sec: 57.19 - lr: 0.025000\n",
      "2021-03-29 12:05:18,080 epoch 25 - iter 276/469 - loss 0.30737253 - samples/sec: 57.31 - lr: 0.025000\n",
      "2021-03-29 12:05:44,600 epoch 25 - iter 322/469 - loss 0.30930130 - samples/sec: 55.52 - lr: 0.025000\n",
      "2021-03-29 12:06:10,691 epoch 25 - iter 368/469 - loss 0.31380535 - samples/sec: 56.43 - lr: 0.025000\n",
      "2021-03-29 12:06:36,837 epoch 25 - iter 414/469 - loss 0.31437458 - samples/sec: 56.31 - lr: 0.025000\n",
      "2021-03-29 12:07:02,166 epoch 25 - iter 460/469 - loss 0.31545627 - samples/sec: 58.13 - lr: 0.025000\n",
      "2021-03-29 12:07:07,527 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:07:07,529 EPOCH 25 done: loss 0.3169 - lr 0.0250000\n",
      "2021-03-29 12:07:23,434 DEV : loss 0.47653523087501526 - score 0.9488\n",
      "2021-03-29 12:07:23,692 BAD EPOCHS (no improvement): 2\n",
      "2021-03-29 12:07:23,694 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:07:49,072 epoch 26 - iter 46/469 - loss 0.35528589 - samples/sec: 58.02 - lr: 0.025000\n",
      "2021-03-29 12:08:16,837 epoch 26 - iter 92/469 - loss 0.33695443 - samples/sec: 53.03 - lr: 0.025000\n",
      "2021-03-29 12:08:42,258 epoch 26 - iter 138/469 - loss 0.33284400 - samples/sec: 57.92 - lr: 0.025000\n",
      "2021-03-29 12:09:07,623 epoch 26 - iter 184/469 - loss 0.31667004 - samples/sec: 58.05 - lr: 0.025000\n",
      "2021-03-29 12:09:33,914 epoch 26 - iter 230/469 - loss 0.30962503 - samples/sec: 56.00 - lr: 0.025000\n",
      "2021-03-29 12:10:01,874 epoch 26 - iter 276/469 - loss 0.31381134 - samples/sec: 52.66 - lr: 0.025000\n",
      "2021-03-29 12:10:29,454 epoch 26 - iter 322/469 - loss 0.31711892 - samples/sec: 53.38 - lr: 0.025000\n",
      "2021-03-29 12:10:57,678 epoch 26 - iter 368/469 - loss 0.31422241 - samples/sec: 52.17 - lr: 0.025000\n",
      "2021-03-29 12:11:23,759 epoch 26 - iter 414/469 - loss 0.30866191 - samples/sec: 56.46 - lr: 0.025000\n",
      "2021-03-29 12:11:49,955 epoch 26 - iter 460/469 - loss 0.30627564 - samples/sec: 56.20 - lr: 0.025000\n",
      "2021-03-29 12:11:54,995 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:11:54,997 EPOCH 26 done: loss 0.3053 - lr 0.0250000\n",
      "2021-03-29 12:12:10,956 DEV : loss 0.46988824009895325 - score 0.9501\n",
      "2021-03-29 12:12:11,232 BAD EPOCHS (no improvement): 3\n",
      "2021-03-29 12:12:11,234 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:12:37,049 epoch 27 - iter 46/469 - loss 0.30962127 - samples/sec: 57.03 - lr: 0.025000\n",
      "2021-03-29 12:13:03,229 epoch 27 - iter 92/469 - loss 0.30448891 - samples/sec: 56.25 - lr: 0.025000\n",
      "2021-03-29 12:13:32,195 epoch 27 - iter 138/469 - loss 0.29818559 - samples/sec: 50.82 - lr: 0.025000\n",
      "2021-03-29 12:13:59,075 epoch 27 - iter 184/469 - loss 0.29692943 - samples/sec: 54.78 - lr: 0.025000\n",
      "2021-03-29 12:14:26,439 epoch 27 - iter 230/469 - loss 0.29457608 - samples/sec: 53.79 - lr: 0.025000\n",
      "2021-03-29 12:14:53,707 epoch 27 - iter 276/469 - loss 0.29940873 - samples/sec: 54.00 - lr: 0.025000\n",
      "2021-03-29 12:15:20,536 epoch 27 - iter 322/469 - loss 0.30227200 - samples/sec: 54.88 - lr: 0.025000\n",
      "2021-03-29 12:15:49,553 epoch 27 - iter 368/469 - loss 0.30958797 - samples/sec: 50.74 - lr: 0.025000\n",
      "2021-03-29 12:16:15,822 epoch 27 - iter 414/469 - loss 0.31063165 - samples/sec: 56.05 - lr: 0.025000\n",
      "2021-03-29 12:16:41,891 epoch 27 - iter 460/469 - loss 0.31101354 - samples/sec: 56.48 - lr: 0.025000\n",
      "2021-03-29 12:16:47,056 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:16:47,057 EPOCH 27 done: loss 0.3106 - lr 0.0250000\n",
      "2021-03-29 12:17:03,137 DEV : loss 0.4671732783317566 - score 0.9473\n",
      "Epoch    27: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2021-03-29 12:17:03,393 BAD EPOCHS (no improvement): 4\n",
      "2021-03-29 12:17:03,393 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:17:30,465 epoch 28 - iter 46/469 - loss 0.31995629 - samples/sec: 54.39 - lr: 0.012500\n",
      "2021-03-29 12:17:58,103 epoch 28 - iter 92/469 - loss 0.32030327 - samples/sec: 53.27 - lr: 0.012500\n",
      "2021-03-29 12:18:24,523 epoch 28 - iter 138/469 - loss 0.29970075 - samples/sec: 55.73 - lr: 0.012500\n",
      "2021-03-29 12:18:52,602 epoch 28 - iter 184/469 - loss 0.29775200 - samples/sec: 52.43 - lr: 0.012500\n",
      "2021-03-29 12:19:19,179 epoch 28 - iter 230/469 - loss 0.30921207 - samples/sec: 55.39 - lr: 0.012500\n",
      "2021-03-29 12:19:45,064 epoch 28 - iter 276/469 - loss 0.30164188 - samples/sec: 56.87 - lr: 0.012500\n",
      "2021-03-29 12:20:12,404 epoch 28 - iter 322/469 - loss 0.30131272 - samples/sec: 53.85 - lr: 0.012500\n",
      "2021-03-29 12:20:39,276 epoch 28 - iter 368/469 - loss 0.30005970 - samples/sec: 54.79 - lr: 0.012500\n",
      "2021-03-29 12:21:06,524 epoch 28 - iter 414/469 - loss 0.30219796 - samples/sec: 54.03 - lr: 0.012500\n",
      "2021-03-29 12:21:33,312 epoch 28 - iter 460/469 - loss 0.30265375 - samples/sec: 54.96 - lr: 0.012500\n",
      "2021-03-29 12:21:37,795 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:21:37,796 EPOCH 28 done: loss 0.3022 - lr 0.0125000\n",
      "2021-03-29 12:21:54,320 DEV : loss 0.4711557924747467 - score 0.9501\n",
      "2021-03-29 12:21:54,589 BAD EPOCHS (no improvement): 1\n",
      "2021-03-29 12:21:54,591 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:22:20,897 epoch 29 - iter 46/469 - loss 0.27979329 - samples/sec: 55.96 - lr: 0.012500\n",
      "2021-03-29 12:22:48,419 epoch 29 - iter 92/469 - loss 0.27299235 - samples/sec: 53.49 - lr: 0.012500\n",
      "2021-03-29 12:23:14,304 epoch 29 - iter 138/469 - loss 0.26998012 - samples/sec: 56.88 - lr: 0.012500\n",
      "2021-03-29 12:23:40,466 epoch 29 - iter 184/469 - loss 0.27348467 - samples/sec: 56.28 - lr: 0.012500\n",
      "2021-03-29 12:24:09,270 epoch 29 - iter 230/469 - loss 0.27096423 - samples/sec: 51.12 - lr: 0.012500\n",
      "2021-03-29 12:24:37,162 epoch 29 - iter 276/469 - loss 0.26943217 - samples/sec: 52.79 - lr: 0.012500\n",
      "2021-03-29 12:25:04,146 epoch 29 - iter 322/469 - loss 0.27013053 - samples/sec: 54.57 - lr: 0.012500\n",
      "2021-03-29 12:25:30,243 epoch 29 - iter 368/469 - loss 0.27409075 - samples/sec: 56.42 - lr: 0.012500\n",
      "2021-03-29 12:25:57,852 epoch 29 - iter 414/469 - loss 0.27466206 - samples/sec: 53.32 - lr: 0.012500\n",
      "2021-03-29 12:26:24,367 epoch 29 - iter 460/469 - loss 0.27751822 - samples/sec: 55.52 - lr: 0.012500\n",
      "2021-03-29 12:26:29,319 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:26:29,320 EPOCH 29 done: loss 0.2771 - lr 0.0125000\n",
      "2021-03-29 12:26:45,303 DEV : loss 0.47472083568573 - score 0.9508\n",
      "2021-03-29 12:26:45,567 BAD EPOCHS (no improvement): 2\n",
      "2021-03-29 12:26:45,571 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:27:13,424 epoch 30 - iter 46/469 - loss 0.28559845 - samples/sec: 52.86 - lr: 0.012500\n",
      "2021-03-29 12:27:39,844 epoch 30 - iter 92/469 - loss 0.28047729 - samples/sec: 55.72 - lr: 0.012500\n",
      "2021-03-29 12:28:06,352 epoch 30 - iter 138/469 - loss 0.28439781 - samples/sec: 55.54 - lr: 0.012500\n",
      "2021-03-29 12:28:33,065 epoch 30 - iter 184/469 - loss 0.28266898 - samples/sec: 55.11 - lr: 0.012500\n",
      "2021-03-29 12:29:02,486 epoch 30 - iter 230/469 - loss 0.28215156 - samples/sec: 50.04 - lr: 0.012500\n",
      "2021-03-29 12:29:29,623 epoch 30 - iter 276/469 - loss 0.28172661 - samples/sec: 54.26 - lr: 0.012500\n",
      "2021-03-29 12:29:55,719 epoch 30 - iter 322/469 - loss 0.28821800 - samples/sec: 56.42 - lr: 0.012500\n",
      "2021-03-29 12:30:22,309 epoch 30 - iter 368/469 - loss 0.28522667 - samples/sec: 55.37 - lr: 0.012500\n",
      "2021-03-29 12:30:48,666 epoch 30 - iter 414/469 - loss 0.28324247 - samples/sec: 55.85 - lr: 0.012500\n",
      "2021-03-29 12:31:16,803 epoch 30 - iter 460/469 - loss 0.28419190 - samples/sec: 52.32 - lr: 0.012500\n",
      "2021-03-29 12:31:22,277 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:31:22,279 EPOCH 30 done: loss 0.2854 - lr 0.0125000\n",
      "2021-03-29 12:31:38,220 DEV : loss 0.46848422288894653 - score 0.9502\n",
      "2021-03-29 12:31:38,480 BAD EPOCHS (no improvement): 3\n",
      "2021-03-29 12:31:38,482 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:32:05,711 epoch 31 - iter 46/469 - loss 0.29595480 - samples/sec: 54.07 - lr: 0.012500\n",
      "2021-03-29 12:32:31,856 epoch 31 - iter 92/469 - loss 0.28547290 - samples/sec: 56.31 - lr: 0.012500\n",
      "2021-03-29 12:32:59,439 epoch 31 - iter 138/469 - loss 0.28207329 - samples/sec: 53.37 - lr: 0.012500\n",
      "2021-03-29 12:33:24,149 epoch 31 - iter 184/469 - loss 0.28333133 - samples/sec: 59.59 - lr: 0.012500\n",
      "2021-03-29 12:33:50,748 epoch 31 - iter 230/469 - loss 0.28105667 - samples/sec: 55.36 - lr: 0.012500\n",
      "2021-03-29 12:34:19,624 epoch 31 - iter 276/469 - loss 0.28273407 - samples/sec: 50.99 - lr: 0.012500\n",
      "2021-03-29 12:34:46,244 epoch 31 - iter 322/469 - loss 0.28532462 - samples/sec: 55.31 - lr: 0.012500\n",
      "2021-03-29 12:35:12,933 epoch 31 - iter 368/469 - loss 0.28381553 - samples/sec: 55.16 - lr: 0.012500\n",
      "2021-03-29 12:35:40,737 epoch 31 - iter 414/469 - loss 0.28318490 - samples/sec: 52.95 - lr: 0.012500\n",
      "2021-03-29 12:36:07,226 epoch 31 - iter 460/469 - loss 0.27991981 - samples/sec: 55.59 - lr: 0.012500\n",
      "2021-03-29 12:36:12,488 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:36:12,490 EPOCH 31 done: loss 0.2808 - lr 0.0125000\n",
      "2021-03-29 12:36:30,289 DEV : loss 0.47812163829803467 - score 0.9508\n",
      "Epoch    31: reducing learning rate of group 0 to 6.2500e-03.\n",
      "2021-03-29 12:36:30,555 BAD EPOCHS (no improvement): 4\n",
      "2021-03-29 12:36:30,556 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:36:55,810 epoch 32 - iter 46/469 - loss 0.25507908 - samples/sec: 58.31 - lr: 0.006250\n",
      "2021-03-29 12:37:21,886 epoch 32 - iter 92/469 - loss 0.26797558 - samples/sec: 56.46 - lr: 0.006250\n",
      "2021-03-29 12:37:47,148 epoch 32 - iter 138/469 - loss 0.27936752 - samples/sec: 58.29 - lr: 0.006250\n",
      "2021-03-29 12:38:22,024 epoch 32 - iter 184/469 - loss 0.29162159 - samples/sec: 42.21 - lr: 0.006250\n",
      "2021-03-29 12:38:49,566 epoch 32 - iter 230/469 - loss 0.28302809 - samples/sec: 53.45 - lr: 0.006250\n",
      "2021-03-29 12:39:15,108 epoch 32 - iter 276/469 - loss 0.28331682 - samples/sec: 57.65 - lr: 0.006250\n",
      "2021-03-29 12:39:42,984 epoch 32 - iter 322/469 - loss 0.28159762 - samples/sec: 52.81 - lr: 0.006250\n",
      "2021-03-29 12:40:12,771 epoch 32 - iter 368/469 - loss 0.27822361 - samples/sec: 49.43 - lr: 0.006250\n",
      "2021-03-29 12:40:40,355 epoch 32 - iter 414/469 - loss 0.28093673 - samples/sec: 53.37 - lr: 0.006250\n",
      "2021-03-29 12:41:08,453 epoch 32 - iter 460/469 - loss 0.28041527 - samples/sec: 52.40 - lr: 0.006250\n",
      "2021-03-29 12:41:13,527 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:41:13,529 EPOCH 32 done: loss 0.2817 - lr 0.0062500\n",
      "2021-03-29 12:41:30,109 DEV : loss 0.47695761919021606 - score 0.951\n",
      "2021-03-29 12:41:30,371 BAD EPOCHS (no improvement): 1\n",
      "2021-03-29 12:41:30,375 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:41:57,957 epoch 33 - iter 46/469 - loss 0.25275591 - samples/sec: 53.38 - lr: 0.006250\n",
      "2021-03-29 12:42:25,635 epoch 33 - iter 92/469 - loss 0.26154217 - samples/sec: 53.19 - lr: 0.006250\n",
      "2021-03-29 12:42:53,669 epoch 33 - iter 138/469 - loss 0.26844468 - samples/sec: 52.52 - lr: 0.006250\n",
      "2021-03-29 12:43:20,356 epoch 33 - iter 184/469 - loss 0.27027609 - samples/sec: 55.17 - lr: 0.006250\n",
      "2021-03-29 12:43:46,809 epoch 33 - iter 230/469 - loss 0.27430591 - samples/sec: 55.65 - lr: 0.006250\n",
      "2021-03-29 12:44:14,017 epoch 33 - iter 276/469 - loss 0.27852111 - samples/sec: 54.11 - lr: 0.006250\n",
      "2021-03-29 12:44:40,818 epoch 33 - iter 322/469 - loss 0.27749586 - samples/sec: 54.93 - lr: 0.006250\n",
      "2021-03-29 12:45:10,586 epoch 33 - iter 368/469 - loss 0.27845600 - samples/sec: 49.46 - lr: 0.006250\n",
      "2021-03-29 12:45:35,975 epoch 33 - iter 414/469 - loss 0.27558533 - samples/sec: 57.98 - lr: 0.006250\n",
      "2021-03-29 12:46:02,878 epoch 33 - iter 460/469 - loss 0.27225365 - samples/sec: 54.72 - lr: 0.006250\n",
      "2021-03-29 12:46:07,831 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:46:07,832 EPOCH 33 done: loss 0.2713 - lr 0.0062500\n",
      "2021-03-29 12:46:23,822 DEV : loss 0.47558075189590454 - score 0.9493\n",
      "2021-03-29 12:46:24,094 BAD EPOCHS (no improvement): 2\n",
      "2021-03-29 12:46:24,097 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:46:51,746 epoch 34 - iter 46/469 - loss 0.25565217 - samples/sec: 53.26 - lr: 0.006250\n",
      "2021-03-29 12:47:17,612 epoch 34 - iter 92/469 - loss 0.25845272 - samples/sec: 56.91 - lr: 0.006250\n",
      "2021-03-29 12:47:44,561 epoch 34 - iter 138/469 - loss 0.26536104 - samples/sec: 54.63 - lr: 0.006250\n",
      "2021-03-29 12:48:11,348 epoch 34 - iter 184/469 - loss 0.26885412 - samples/sec: 54.97 - lr: 0.006250\n",
      "2021-03-29 12:48:37,648 epoch 34 - iter 230/469 - loss 0.27049197 - samples/sec: 55.99 - lr: 0.006250\n",
      "2021-03-29 12:49:04,277 epoch 34 - iter 276/469 - loss 0.27157890 - samples/sec: 55.28 - lr: 0.006250\n",
      "2021-03-29 12:49:32,206 epoch 34 - iter 322/469 - loss 0.27447162 - samples/sec: 52.71 - lr: 0.006250\n",
      "2021-03-29 12:49:58,958 epoch 34 - iter 368/469 - loss 0.27093215 - samples/sec: 55.03 - lr: 0.006250\n",
      "2021-03-29 12:50:27,554 epoch 34 - iter 414/469 - loss 0.27435672 - samples/sec: 51.48 - lr: 0.006250\n",
      "2021-03-29 12:50:54,504 epoch 34 - iter 460/469 - loss 0.27654025 - samples/sec: 54.62 - lr: 0.006250\n",
      "2021-03-29 12:50:59,915 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:50:59,916 EPOCH 34 done: loss 0.2762 - lr 0.0062500\n",
      "2021-03-29 12:51:17,114 DEV : loss 0.47201359272003174 - score 0.951\n",
      "2021-03-29 12:51:17,382 BAD EPOCHS (no improvement): 3\n",
      "2021-03-29 12:51:17,384 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:51:43,593 epoch 35 - iter 46/469 - loss 0.28775362 - samples/sec: 56.18 - lr: 0.006250\n",
      "2021-03-29 12:52:09,412 epoch 35 - iter 92/469 - loss 0.27498326 - samples/sec: 57.02 - lr: 0.006250\n",
      "2021-03-29 12:52:36,431 epoch 35 - iter 138/469 - loss 0.27222141 - samples/sec: 54.48 - lr: 0.006250\n",
      "2021-03-29 12:53:03,355 epoch 35 - iter 184/469 - loss 0.27178086 - samples/sec: 54.68 - lr: 0.006250\n",
      "2021-03-29 12:53:31,019 epoch 35 - iter 230/469 - loss 0.26725079 - samples/sec: 53.23 - lr: 0.006250\n",
      "2021-03-29 12:53:58,272 epoch 35 - iter 276/469 - loss 0.26644071 - samples/sec: 54.02 - lr: 0.006250\n",
      "2021-03-29 12:54:24,301 epoch 35 - iter 322/469 - loss 0.27070853 - samples/sec: 56.57 - lr: 0.006250\n",
      "2021-03-29 12:54:51,471 epoch 35 - iter 368/469 - loss 0.26963523 - samples/sec: 54.19 - lr: 0.006250\n",
      "2021-03-29 12:55:18,747 epoch 35 - iter 414/469 - loss 0.27018061 - samples/sec: 53.97 - lr: 0.006250\n",
      "2021-03-29 12:55:48,175 epoch 35 - iter 460/469 - loss 0.27394675 - samples/sec: 50.03 - lr: 0.006250\n",
      "2021-03-29 12:55:53,059 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:55:53,060 EPOCH 35 done: loss 0.2740 - lr 0.0062500\n",
      "2021-03-29 12:56:08,969 DEV : loss 0.4701985716819763 - score 0.9514\n",
      "Epoch    35: reducing learning rate of group 0 to 3.1250e-03.\n",
      "2021-03-29 12:56:09,221 BAD EPOCHS (no improvement): 4\n",
      "2021-03-29 12:56:09,223 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 12:56:34,874 epoch 36 - iter 46/469 - loss 0.29836449 - samples/sec: 57.40 - lr: 0.003125\n",
      "2021-03-29 12:57:00,308 epoch 36 - iter 92/469 - loss 0.28343524 - samples/sec: 57.88 - lr: 0.003125\n",
      "2021-03-29 12:57:28,070 epoch 36 - iter 138/469 - loss 0.28544923 - samples/sec: 53.03 - lr: 0.003125\n",
      "2021-03-29 12:57:55,053 epoch 36 - iter 184/469 - loss 0.28014820 - samples/sec: 54.56 - lr: 0.003125\n",
      "2021-03-29 12:58:22,194 epoch 36 - iter 230/469 - loss 0.27925346 - samples/sec: 54.24 - lr: 0.003125\n",
      "2021-03-29 12:58:48,744 epoch 36 - iter 276/469 - loss 0.27514559 - samples/sec: 55.45 - lr: 0.003125\n",
      "2021-03-29 12:59:14,783 epoch 36 - iter 322/469 - loss 0.27327233 - samples/sec: 56.55 - lr: 0.003125\n",
      "2021-03-29 12:59:41,499 epoch 36 - iter 368/469 - loss 0.27426741 - samples/sec: 55.10 - lr: 0.003125\n",
      "2021-03-29 13:00:08,874 epoch 36 - iter 414/469 - loss 0.27294507 - samples/sec: 53.78 - lr: 0.003125\n",
      "2021-03-29 13:00:37,819 epoch 36 - iter 460/469 - loss 0.27558254 - samples/sec: 50.86 - lr: 0.003125\n",
      "2021-03-29 13:00:43,247 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:00:43,249 EPOCH 36 done: loss 0.2779 - lr 0.0031250\n",
      "2021-03-29 13:00:59,400 DEV : loss 0.47412025928497314 - score 0.9513\n",
      "2021-03-29 13:00:59,635 BAD EPOCHS (no improvement): 1\n",
      "2021-03-29 13:00:59,637 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:01:26,675 epoch 37 - iter 46/469 - loss 0.25338481 - samples/sec: 54.46 - lr: 0.003125\n",
      "2021-03-29 13:01:53,908 epoch 37 - iter 92/469 - loss 0.25096197 - samples/sec: 54.06 - lr: 0.003125\n",
      "2021-03-29 13:02:20,274 epoch 37 - iter 138/469 - loss 0.24454362 - samples/sec: 55.84 - lr: 0.003125\n",
      "2021-03-29 13:02:47,611 epoch 37 - iter 184/469 - loss 0.25267721 - samples/sec: 53.87 - lr: 0.003125\n",
      "2021-03-29 13:03:14,638 epoch 37 - iter 230/469 - loss 0.25482205 - samples/sec: 54.48 - lr: 0.003125\n",
      "2021-03-29 13:03:42,507 epoch 37 - iter 276/469 - loss 0.25760239 - samples/sec: 52.83 - lr: 0.003125\n",
      "2021-03-29 13:04:08,969 epoch 37 - iter 322/469 - loss 0.25495986 - samples/sec: 55.64 - lr: 0.003125\n",
      "2021-03-29 13:04:35,419 epoch 37 - iter 368/469 - loss 0.25427563 - samples/sec: 55.66 - lr: 0.003125\n",
      "2021-03-29 13:05:01,253 epoch 37 - iter 414/469 - loss 0.25715108 - samples/sec: 56.99 - lr: 0.003125\n",
      "2021-03-29 13:05:27,699 epoch 37 - iter 460/469 - loss 0.25927522 - samples/sec: 55.67 - lr: 0.003125\n",
      "2021-03-29 13:05:32,930 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:05:32,932 EPOCH 37 done: loss 0.2590 - lr 0.0031250\n",
      "2021-03-29 13:05:50,850 DEV : loss 0.4756969213485718 - score 0.9509\n",
      "2021-03-29 13:05:51,153 BAD EPOCHS (no improvement): 2\n",
      "2021-03-29 13:05:51,156 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:06:17,140 epoch 38 - iter 46/469 - loss 0.25701201 - samples/sec: 56.67 - lr: 0.003125\n",
      "2021-03-29 13:06:44,086 epoch 38 - iter 92/469 - loss 0.26880486 - samples/sec: 54.64 - lr: 0.003125\n",
      "2021-03-29 13:07:11,153 epoch 38 - iter 138/469 - loss 0.26669555 - samples/sec: 54.39 - lr: 0.003125\n",
      "2021-03-29 13:07:38,810 epoch 38 - iter 184/469 - loss 0.25968969 - samples/sec: 53.23 - lr: 0.003125\n",
      "2021-03-29 13:08:05,749 epoch 38 - iter 230/469 - loss 0.26306297 - samples/sec: 54.65 - lr: 0.003125\n",
      "2021-03-29 13:08:31,797 epoch 38 - iter 276/469 - loss 0.26489895 - samples/sec: 56.52 - lr: 0.003125\n",
      "2021-03-29 13:08:58,385 epoch 38 - iter 322/469 - loss 0.26636947 - samples/sec: 55.37 - lr: 0.003125\n",
      "2021-03-29 13:09:24,549 epoch 38 - iter 368/469 - loss 0.26542030 - samples/sec: 56.27 - lr: 0.003125\n",
      "2021-03-29 13:09:51,643 epoch 38 - iter 414/469 - loss 0.26717650 - samples/sec: 54.35 - lr: 0.003125\n",
      "2021-03-29 13:10:18,876 epoch 38 - iter 460/469 - loss 0.26757576 - samples/sec: 54.06 - lr: 0.003125\n",
      "2021-03-29 13:10:23,759 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:10:23,760 EPOCH 38 done: loss 0.2658 - lr 0.0031250\n",
      "2021-03-29 13:10:39,836 DEV : loss 0.4762319028377533 - score 0.9511\n",
      "2021-03-29 13:10:40,091 BAD EPOCHS (no improvement): 3\n",
      "2021-03-29 13:10:40,093 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:11:08,589 epoch 39 - iter 46/469 - loss 0.27796755 - samples/sec: 51.67 - lr: 0.003125\n",
      "2021-03-29 13:11:34,926 epoch 39 - iter 92/469 - loss 0.26922446 - samples/sec: 55.90 - lr: 0.003125\n",
      "2021-03-29 13:12:02,441 epoch 39 - iter 138/469 - loss 0.27208576 - samples/sec: 53.51 - lr: 0.003125\n",
      "2021-03-29 13:12:29,871 epoch 39 - iter 184/469 - loss 0.27234409 - samples/sec: 53.67 - lr: 0.003125\n",
      "2021-03-29 13:12:55,524 epoch 39 - iter 230/469 - loss 0.27186921 - samples/sec: 57.39 - lr: 0.003125\n",
      "2021-03-29 13:13:22,213 epoch 39 - iter 276/469 - loss 0.26790809 - samples/sec: 55.17 - lr: 0.003125\n",
      "2021-03-29 13:13:47,636 epoch 39 - iter 322/469 - loss 0.26776430 - samples/sec: 57.92 - lr: 0.003125\n",
      "2021-03-29 13:14:13,342 epoch 39 - iter 368/469 - loss 0.26869509 - samples/sec: 57.27 - lr: 0.003125\n",
      "2021-03-29 13:14:38,383 epoch 39 - iter 414/469 - loss 0.26761162 - samples/sec: 58.80 - lr: 0.003125\n",
      "2021-03-29 13:15:04,155 epoch 39 - iter 460/469 - loss 0.26773515 - samples/sec: 57.13 - lr: 0.003125\n",
      "2021-03-29 13:15:08,439 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:15:08,441 EPOCH 39 done: loss 0.2666 - lr 0.0031250\n",
      "2021-03-29 13:15:23,476 DEV : loss 0.475778728723526 - score 0.9508\n",
      "Epoch    39: reducing learning rate of group 0 to 1.5625e-03.\n",
      "2021-03-29 13:15:23,720 BAD EPOCHS (no improvement): 4\n",
      "2021-03-29 13:15:23,722 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:15:49,139 epoch 40 - iter 46/469 - loss 0.25601127 - samples/sec: 57.94 - lr: 0.001563\n",
      "2021-03-29 13:16:15,977 epoch 40 - iter 92/469 - loss 0.25848588 - samples/sec: 54.86 - lr: 0.001563\n",
      "2021-03-29 13:16:43,128 epoch 40 - iter 138/469 - loss 0.25885078 - samples/sec: 54.22 - lr: 0.001563\n",
      "2021-03-29 13:17:09,268 epoch 40 - iter 184/469 - loss 0.25954182 - samples/sec: 56.32 - lr: 0.001563\n",
      "2021-03-29 13:17:35,497 epoch 40 - iter 230/469 - loss 0.25757734 - samples/sec: 56.14 - lr: 0.001563\n",
      "2021-03-29 13:18:01,246 epoch 40 - iter 276/469 - loss 0.25919802 - samples/sec: 57.18 - lr: 0.001563\n",
      "2021-03-29 13:18:25,964 epoch 40 - iter 322/469 - loss 0.26476347 - samples/sec: 59.56 - lr: 0.001563\n",
      "2021-03-29 13:18:51,237 epoch 40 - iter 368/469 - loss 0.26586692 - samples/sec: 58.26 - lr: 0.001563\n",
      "2021-03-29 13:19:17,504 epoch 40 - iter 414/469 - loss 0.26685668 - samples/sec: 56.05 - lr: 0.001563\n",
      "2021-03-29 13:19:43,346 epoch 40 - iter 460/469 - loss 0.26964609 - samples/sec: 56.98 - lr: 0.001563\n",
      "2021-03-29 13:19:48,118 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:19:48,120 EPOCH 40 done: loss 0.2695 - lr 0.0015625\n",
      "2021-03-29 13:20:03,886 DEV : loss 0.47583886981010437 - score 0.9509\n",
      "2021-03-29 13:20:04,172 BAD EPOCHS (no improvement): 1\n",
      "2021-03-29 13:20:04,174 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:20:29,918 epoch 41 - iter 46/469 - loss 0.23078505 - samples/sec: 57.19 - lr: 0.001563\n",
      "2021-03-29 13:20:57,315 epoch 41 - iter 92/469 - loss 0.24625601 - samples/sec: 53.73 - lr: 0.001563\n",
      "2021-03-29 13:21:22,668 epoch 41 - iter 138/469 - loss 0.24806901 - samples/sec: 58.07 - lr: 0.001563\n",
      "2021-03-29 13:21:50,029 epoch 41 - iter 184/469 - loss 0.25083651 - samples/sec: 53.81 - lr: 0.001563\n",
      "2021-03-29 13:22:15,501 epoch 41 - iter 230/469 - loss 0.25232231 - samples/sec: 57.80 - lr: 0.001563\n",
      "2021-03-29 13:22:41,621 epoch 41 - iter 276/469 - loss 0.25807142 - samples/sec: 56.36 - lr: 0.001563\n",
      "2021-03-29 13:23:07,012 epoch 41 - iter 322/469 - loss 0.26282686 - samples/sec: 57.99 - lr: 0.001563\n",
      "2021-03-29 13:23:32,849 epoch 41 - iter 368/469 - loss 0.26397835 - samples/sec: 56.98 - lr: 0.001563\n",
      "2021-03-29 13:23:58,241 epoch 41 - iter 414/469 - loss 0.26496019 - samples/sec: 57.99 - lr: 0.001563\n",
      "2021-03-29 13:24:23,928 epoch 41 - iter 460/469 - loss 0.26524782 - samples/sec: 57.31 - lr: 0.001563\n",
      "2021-03-29 13:24:28,804 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:24:28,805 EPOCH 41 done: loss 0.2649 - lr 0.0015625\n",
      "2021-03-29 13:24:43,892 DEV : loss 0.475521445274353 - score 0.9509\n",
      "2021-03-29 13:24:44,168 BAD EPOCHS (no improvement): 2\n",
      "2021-03-29 13:24:44,170 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:25:09,597 epoch 42 - iter 46/469 - loss 0.25061560 - samples/sec: 57.91 - lr: 0.001563\n",
      "2021-03-29 13:25:35,451 epoch 42 - iter 92/469 - loss 0.26731010 - samples/sec: 56.94 - lr: 0.001563\n",
      "2021-03-29 13:26:00,572 epoch 42 - iter 138/469 - loss 0.25538288 - samples/sec: 58.60 - lr: 0.001563\n",
      "2021-03-29 13:26:25,316 epoch 42 - iter 184/469 - loss 0.25646499 - samples/sec: 59.51 - lr: 0.001563\n",
      "2021-03-29 13:26:54,476 epoch 42 - iter 230/469 - loss 0.26867702 - samples/sec: 50.48 - lr: 0.001563\n",
      "2021-03-29 13:27:20,119 epoch 42 - iter 276/469 - loss 0.26725368 - samples/sec: 57.42 - lr: 0.001563\n",
      "2021-03-29 13:27:46,562 epoch 42 - iter 322/469 - loss 0.26195402 - samples/sec: 55.67 - lr: 0.001563\n",
      "2021-03-29 13:28:12,346 epoch 42 - iter 368/469 - loss 0.26524113 - samples/sec: 57.10 - lr: 0.001563\n",
      "2021-03-29 13:28:37,464 epoch 42 - iter 414/469 - loss 0.26655914 - samples/sec: 58.61 - lr: 0.001563\n",
      "2021-03-29 13:29:03,446 epoch 42 - iter 460/469 - loss 0.26445836 - samples/sec: 56.66 - lr: 0.001563\n",
      "2021-03-29 13:29:07,889 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:29:07,891 EPOCH 42 done: loss 0.2634 - lr 0.0015625\n",
      "2021-03-29 13:29:23,796 DEV : loss 0.47555238008499146 - score 0.9511\n",
      "2021-03-29 13:29:24,085 BAD EPOCHS (no improvement): 3\n",
      "2021-03-29 13:29:24,086 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:29:49,061 epoch 43 - iter 46/469 - loss 0.23835171 - samples/sec: 58.96 - lr: 0.001563\n",
      "2021-03-29 13:30:14,549 epoch 43 - iter 92/469 - loss 0.25130502 - samples/sec: 57.76 - lr: 0.001563\n",
      "2021-03-29 13:30:40,879 epoch 43 - iter 138/469 - loss 0.25436153 - samples/sec: 55.92 - lr: 0.001563\n",
      "2021-03-29 13:31:05,776 epoch 43 - iter 184/469 - loss 0.24994578 - samples/sec: 59.13 - lr: 0.001563\n",
      "2021-03-29 13:31:31,589 epoch 43 - iter 230/469 - loss 0.24833951 - samples/sec: 57.03 - lr: 0.001563\n",
      "2021-03-29 13:31:58,929 epoch 43 - iter 276/469 - loss 0.25103026 - samples/sec: 53.85 - lr: 0.001563\n",
      "2021-03-29 13:32:25,783 epoch 43 - iter 322/469 - loss 0.25126448 - samples/sec: 54.83 - lr: 0.001563\n",
      "2021-03-29 13:32:51,397 epoch 43 - iter 368/469 - loss 0.25660037 - samples/sec: 57.47 - lr: 0.001563\n",
      "2021-03-29 13:33:17,255 epoch 43 - iter 414/469 - loss 0.26114895 - samples/sec: 56.94 - lr: 0.001563\n",
      "2021-03-29 13:33:43,935 epoch 43 - iter 460/469 - loss 0.26319552 - samples/sec: 55.19 - lr: 0.001563\n",
      "2021-03-29 13:33:48,755 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:33:48,758 EPOCH 43 done: loss 0.2628 - lr 0.0015625\n",
      "2021-03-29 13:34:04,972 DEV : loss 0.4765179455280304 - score 0.9509\n",
      "Epoch    43: reducing learning rate of group 0 to 7.8125e-04.\n",
      "2021-03-29 13:34:05,266 BAD EPOCHS (no improvement): 4\n",
      "2021-03-29 13:34:05,267 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:34:30,645 epoch 44 - iter 46/469 - loss 0.22823238 - samples/sec: 58.02 - lr: 0.000781\n",
      "2021-03-29 13:34:58,301 epoch 44 - iter 92/469 - loss 0.24483575 - samples/sec: 53.24 - lr: 0.000781\n",
      "2021-03-29 13:35:24,862 epoch 44 - iter 138/469 - loss 0.26179372 - samples/sec: 55.43 - lr: 0.000781\n",
      "2021-03-29 13:35:50,397 epoch 44 - iter 184/469 - loss 0.25911181 - samples/sec: 57.65 - lr: 0.000781\n",
      "2021-03-29 13:36:16,762 epoch 44 - iter 230/469 - loss 0.25415337 - samples/sec: 55.84 - lr: 0.000781\n",
      "2021-03-29 13:36:42,330 epoch 44 - iter 276/469 - loss 0.25855859 - samples/sec: 57.59 - lr: 0.000781\n",
      "2021-03-29 13:37:08,330 epoch 44 - iter 322/469 - loss 0.26626297 - samples/sec: 56.63 - lr: 0.000781\n",
      "2021-03-29 13:37:36,343 epoch 44 - iter 368/469 - loss 0.26828320 - samples/sec: 52.56 - lr: 0.000781\n",
      "2021-03-29 13:38:01,683 epoch 44 - iter 414/469 - loss 0.26910265 - samples/sec: 58.11 - lr: 0.000781\n",
      "2021-03-29 13:38:27,897 epoch 44 - iter 460/469 - loss 0.26826948 - samples/sec: 56.17 - lr: 0.000781\n",
      "2021-03-29 13:38:32,521 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:38:32,523 EPOCH 44 done: loss 0.2684 - lr 0.0007813\n",
      "2021-03-29 13:38:47,632 DEV : loss 0.4766770601272583 - score 0.9514\n",
      "2021-03-29 13:38:47,900 BAD EPOCHS (no improvement): 1\n",
      "2021-03-29 13:38:47,902 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:39:13,331 epoch 45 - iter 46/469 - loss 0.22799507 - samples/sec: 57.90 - lr: 0.000781\n",
      "2021-03-29 13:39:39,543 epoch 45 - iter 92/469 - loss 0.24224880 - samples/sec: 56.16 - lr: 0.000781\n",
      "2021-03-29 13:40:05,013 epoch 45 - iter 138/469 - loss 0.25410184 - samples/sec: 57.80 - lr: 0.000781\n",
      "2021-03-29 13:40:30,578 epoch 45 - iter 184/469 - loss 0.25518662 - samples/sec: 57.59 - lr: 0.000781\n",
      "2021-03-29 13:40:55,999 epoch 45 - iter 230/469 - loss 0.24980589 - samples/sec: 57.91 - lr: 0.000781\n",
      "2021-03-29 13:41:20,960 epoch 45 - iter 276/469 - loss 0.25302379 - samples/sec: 58.98 - lr: 0.000781\n",
      "2021-03-29 13:41:46,980 epoch 45 - iter 322/469 - loss 0.25840651 - samples/sec: 56.59 - lr: 0.000781\n",
      "2021-03-29 13:42:13,603 epoch 45 - iter 368/469 - loss 0.26133163 - samples/sec: 55.30 - lr: 0.000781\n",
      "2021-03-29 13:42:43,208 epoch 45 - iter 414/469 - loss 0.26145469 - samples/sec: 49.72 - lr: 0.000781\n",
      "2021-03-29 13:43:08,025 epoch 45 - iter 460/469 - loss 0.25945476 - samples/sec: 59.32 - lr: 0.000781\n",
      "2021-03-29 13:43:12,604 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:43:12,606 EPOCH 45 done: loss 0.2589 - lr 0.0007813\n",
      "2021-03-29 13:43:27,837 DEV : loss 0.47676944732666016 - score 0.9514\n",
      "2021-03-29 13:43:28,105 BAD EPOCHS (no improvement): 2\n",
      "2021-03-29 13:43:28,107 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:43:54,262 epoch 46 - iter 46/469 - loss 0.27462964 - samples/sec: 56.29 - lr: 0.000781\n",
      "2021-03-29 13:44:19,849 epoch 46 - iter 92/469 - loss 0.25634302 - samples/sec: 57.55 - lr: 0.000781\n",
      "2021-03-29 13:44:45,913 epoch 46 - iter 138/469 - loss 0.25466537 - samples/sec: 56.49 - lr: 0.000781\n",
      "2021-03-29 13:45:11,784 epoch 46 - iter 184/469 - loss 0.25865989 - samples/sec: 56.91 - lr: 0.000781\n",
      "2021-03-29 13:45:38,353 epoch 46 - iter 230/469 - loss 0.26466118 - samples/sec: 55.42 - lr: 0.000781\n",
      "2021-03-29 13:46:04,808 epoch 46 - iter 276/469 - loss 0.26730895 - samples/sec: 55.65 - lr: 0.000781\n",
      "2021-03-29 13:46:30,052 epoch 46 - iter 322/469 - loss 0.26373362 - samples/sec: 58.32 - lr: 0.000781\n",
      "2021-03-29 13:46:56,200 epoch 46 - iter 368/469 - loss 0.26199035 - samples/sec: 56.31 - lr: 0.000781\n",
      "2021-03-29 13:47:21,590 epoch 46 - iter 414/469 - loss 0.26477629 - samples/sec: 57.99 - lr: 0.000781\n",
      "2021-03-29 13:47:49,713 epoch 46 - iter 460/469 - loss 0.26375392 - samples/sec: 52.35 - lr: 0.000781\n",
      "2021-03-29 13:47:53,949 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:47:53,951 EPOCH 46 done: loss 0.2636 - lr 0.0007813\n",
      "2021-03-29 13:48:09,012 DEV : loss 0.477838397026062 - score 0.9508\n",
      "2021-03-29 13:48:09,286 BAD EPOCHS (no improvement): 3\n",
      "2021-03-29 13:48:09,288 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:48:34,577 epoch 47 - iter 46/469 - loss 0.25395267 - samples/sec: 58.22 - lr: 0.000781\n",
      "2021-03-29 13:49:00,649 epoch 47 - iter 92/469 - loss 0.25608671 - samples/sec: 56.48 - lr: 0.000781\n",
      "2021-03-29 13:49:26,341 epoch 47 - iter 138/469 - loss 0.24725123 - samples/sec: 57.30 - lr: 0.000781\n",
      "2021-03-29 13:49:52,673 epoch 47 - iter 184/469 - loss 0.25214096 - samples/sec: 55.91 - lr: 0.000781\n",
      "2021-03-29 13:50:19,189 epoch 47 - iter 230/469 - loss 0.24827305 - samples/sec: 55.52 - lr: 0.000781\n",
      "2021-03-29 13:50:45,133 epoch 47 - iter 276/469 - loss 0.24752899 - samples/sec: 56.74 - lr: 0.000781\n",
      "2021-03-29 13:51:10,111 epoch 47 - iter 322/469 - loss 0.25119367 - samples/sec: 58.95 - lr: 0.000781\n",
      "2021-03-29 13:51:36,381 epoch 47 - iter 368/469 - loss 0.25675513 - samples/sec: 56.05 - lr: 0.000781\n",
      "2021-03-29 13:52:02,981 epoch 47 - iter 414/469 - loss 0.25885358 - samples/sec: 55.35 - lr: 0.000781\n",
      "2021-03-29 13:52:28,059 epoch 47 - iter 460/469 - loss 0.26096215 - samples/sec: 58.71 - lr: 0.000781\n",
      "2021-03-29 13:52:32,782 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:52:32,784 EPOCH 47 done: loss 0.2595 - lr 0.0007813\n",
      "2021-03-29 13:52:47,888 DEV : loss 0.4779544174671173 - score 0.9513\n",
      "Epoch    47: reducing learning rate of group 0 to 3.9063e-04.\n",
      "2021-03-29 13:52:48,162 BAD EPOCHS (no improvement): 4\n",
      "2021-03-29 13:52:48,164 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:53:16,922 epoch 48 - iter 46/469 - loss 0.28739457 - samples/sec: 51.20 - lr: 0.000391\n",
      "2021-03-29 13:53:41,777 epoch 48 - iter 92/469 - loss 0.27507854 - samples/sec: 59.23 - lr: 0.000391\n",
      "2021-03-29 13:54:07,185 epoch 48 - iter 138/469 - loss 0.26947737 - samples/sec: 57.95 - lr: 0.000391\n",
      "2021-03-29 13:54:33,241 epoch 48 - iter 184/469 - loss 0.26503232 - samples/sec: 56.50 - lr: 0.000391\n",
      "2021-03-29 13:54:59,440 epoch 48 - iter 230/469 - loss 0.26007460 - samples/sec: 56.20 - lr: 0.000391\n",
      "2021-03-29 13:55:26,085 epoch 48 - iter 276/469 - loss 0.26830322 - samples/sec: 55.25 - lr: 0.000391\n",
      "2021-03-29 13:55:50,766 epoch 48 - iter 322/469 - loss 0.27142230 - samples/sec: 59.67 - lr: 0.000391\n",
      "2021-03-29 13:56:16,405 epoch 48 - iter 368/469 - loss 0.26981698 - samples/sec: 57.42 - lr: 0.000391\n",
      "2021-03-29 13:56:41,386 epoch 48 - iter 414/469 - loss 0.26815456 - samples/sec: 58.93 - lr: 0.000391\n",
      "2021-03-29 13:57:06,842 epoch 48 - iter 460/469 - loss 0.27335239 - samples/sec: 57.83 - lr: 0.000391\n",
      "2021-03-29 13:57:11,634 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:57:11,635 EPOCH 48 done: loss 0.2717 - lr 0.0003906\n",
      "2021-03-29 13:57:26,756 DEV : loss 0.47764354944229126 - score 0.9513\n",
      "2021-03-29 13:57:27,014 BAD EPOCHS (no improvement): 1\n",
      "2021-03-29 13:57:27,016 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 13:57:52,193 epoch 49 - iter 46/469 - loss 0.28003592 - samples/sec: 58.48 - lr: 0.000391\n",
      "2021-03-29 13:58:20,263 epoch 49 - iter 92/469 - loss 0.25858263 - samples/sec: 52.44 - lr: 0.000391\n",
      "2021-03-29 13:58:45,700 epoch 49 - iter 138/469 - loss 0.26594492 - samples/sec: 57.88 - lr: 0.000391\n",
      "2021-03-29 13:59:11,216 epoch 49 - iter 184/469 - loss 0.26754122 - samples/sec: 57.70 - lr: 0.000391\n",
      "2021-03-29 13:59:36,496 epoch 49 - iter 230/469 - loss 0.26562562 - samples/sec: 58.24 - lr: 0.000391\n",
      "2021-03-29 14:00:02,079 epoch 49 - iter 276/469 - loss 0.26734310 - samples/sec: 57.55 - lr: 0.000391\n",
      "2021-03-29 14:00:27,140 epoch 49 - iter 322/469 - loss 0.26232921 - samples/sec: 58.75 - lr: 0.000391\n",
      "2021-03-29 14:00:53,297 epoch 49 - iter 368/469 - loss 0.26312010 - samples/sec: 56.29 - lr: 0.000391\n",
      "2021-03-29 14:01:19,770 epoch 49 - iter 414/469 - loss 0.26355817 - samples/sec: 55.61 - lr: 0.000391\n",
      "2021-03-29 14:01:45,595 epoch 49 - iter 460/469 - loss 0.26360174 - samples/sec: 57.00 - lr: 0.000391\n",
      "2021-03-29 14:01:50,411 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 14:01:50,413 EPOCH 49 done: loss 0.2628 - lr 0.0003906\n",
      "2021-03-29 14:02:05,622 DEV : loss 0.4779199957847595 - score 0.9512\n",
      "2021-03-29 14:02:05,889 BAD EPOCHS (no improvement): 2\n",
      "2021-03-29 14:02:05,891 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 14:02:31,765 epoch 50 - iter 46/469 - loss 0.24745779 - samples/sec: 56.91 - lr: 0.000391\n",
      "2021-03-29 14:02:58,295 epoch 50 - iter 92/469 - loss 0.26438609 - samples/sec: 55.49 - lr: 0.000391\n",
      "2021-03-29 14:03:25,883 epoch 50 - iter 138/469 - loss 0.25999334 - samples/sec: 53.37 - lr: 0.000391\n",
      "2021-03-29 14:03:53,730 epoch 50 - iter 184/469 - loss 0.25674814 - samples/sec: 52.87 - lr: 0.000391\n",
      "2021-03-29 14:04:18,360 epoch 50 - iter 230/469 - loss 0.25702067 - samples/sec: 59.78 - lr: 0.000391\n",
      "2021-03-29 14:04:43,078 epoch 50 - iter 276/469 - loss 0.26031013 - samples/sec: 59.56 - lr: 0.000391\n",
      "2021-03-29 14:05:09,800 epoch 50 - iter 322/469 - loss 0.26419058 - samples/sec: 55.09 - lr: 0.000391\n",
      "2021-03-29 14:05:35,329 epoch 50 - iter 368/469 - loss 0.26340945 - samples/sec: 57.68 - lr: 0.000391\n",
      "2021-03-29 14:06:00,665 epoch 50 - iter 414/469 - loss 0.26441587 - samples/sec: 58.11 - lr: 0.000391\n",
      "2021-03-29 14:06:26,990 epoch 50 - iter 460/469 - loss 0.26369008 - samples/sec: 55.92 - lr: 0.000391\n",
      "2021-03-29 14:06:31,630 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 14:06:31,631 EPOCH 50 done: loss 0.2625 - lr 0.0003906\n",
      "2021-03-29 14:06:46,956 DEV : loss 0.4780750572681427 - score 0.9511\n",
      "2021-03-29 14:06:47,235 BAD EPOCHS (no improvement): 3\n",
      "2021-03-29 14:06:52,501 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 14:06:52,502 Testing using best model ...\n",
      "2021-03-29 14:06:52,683 loading file C:\\Users\\Chiara\\Desktop\\CoNLL_project\\best-model.pt\n",
      "2021-03-29 14:13:14,863 0.9128\t0.9099\t0.9113\n",
      "2021-03-29 14:13:14,869 \n",
      "Results:\n",
      "- F1-score (micro) 0.9113\n",
      "- F1-score (macro) 0.8968\n",
      "\n",
      "By class:\n",
      "LOC        tp: 1540 - fp: 138 - fn: 128 - precision: 0.9178 - recall: 0.9233 - f1-score: 0.9205\n",
      "MISC       tp: 552 - fp: 110 - fn: 150 - precision: 0.8338 - recall: 0.7863 - f1-score: 0.8094\n",
      "ORG        tp: 1477 - fp: 205 - fn: 184 - precision: 0.8781 - recall: 0.8892 - f1-score: 0.8836\n",
      "PER        tp: 1570 - fp: 38 - fn: 47 - precision: 0.9764 - recall: 0.9709 - f1-score: 0.9736\n",
      "2021-03-29 14:13:14,871 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_score': 0.9113317964178046,\n",
       " 'dev_score_history': [0.8875420875420876,\n",
       "  0.9173251763106466,\n",
       "  0.9233884576442795,\n",
       "  0.9309818551806004,\n",
       "  0.934656462871079,\n",
       "  0.9342647925258816,\n",
       "  0.9318181818181818,\n",
       "  0.9364103427945758,\n",
       "  0.9440647937231081,\n",
       "  0.938551263629448,\n",
       "  0.9459686921393705,\n",
       "  0.9449805315727103,\n",
       "  0.9431731824706577,\n",
       "  0.9442002029083532,\n",
       "  0.9415023080151071,\n",
       "  0.9461007242715177,\n",
       "  0.9469958709025027,\n",
       "  0.9483615533653441,\n",
       "  0.9515299671246733,\n",
       "  0.9479544495993252,\n",
       "  0.9493927125506072,\n",
       "  0.9472886493768946,\n",
       "  0.9478728770808811,\n",
       "  0.9487611663576605,\n",
       "  0.9487503155768745,\n",
       "  0.9500883763992929,\n",
       "  0.9472621751198587,\n",
       "  0.9501219614769956,\n",
       "  0.9508169108977598,\n",
       "  0.9502186343760513,\n",
       "  0.9507865735677631,\n",
       "  0.951010101010101,\n",
       "  0.9492723142929251,\n",
       "  0.9509548245983007,\n",
       "  0.9513631773813531,\n",
       "  0.9513468013468014,\n",
       "  0.9508582968697409,\n",
       "  0.9511148506520823,\n",
       "  0.9507617203939062,\n",
       "  0.9508582968697409,\n",
       "  0.9509465713083719,\n",
       "  0.9511148506520823,\n",
       "  0.9509383152402592,\n",
       "  0.9513631773813531,\n",
       "  0.9513631773813531,\n",
       "  0.9507865735677631,\n",
       "  0.9512749305730875,\n",
       "  0.9512749305730875,\n",
       "  0.9511866689109578,\n",
       "  0.9511066229066734],\n",
       " 'train_loss_history': [2.893258567653231,\n",
       "  1.324787630455326,\n",
       "  1.0548082780100898,\n",
       "  0.9059212880093914,\n",
       "  0.8264488234385244,\n",
       "  0.7453205226136169,\n",
       "  0.7000449241669193,\n",
       "  0.6555655338743857,\n",
       "  0.6130803991546,\n",
       "  0.5912664465304377,\n",
       "  0.5592003666769976,\n",
       "  0.5420485645977419,\n",
       "  0.5152830327434073,\n",
       "  0.49320116655023366,\n",
       "  0.4689678143400119,\n",
       "  0.4337491836629188,\n",
       "  0.40940180700470896,\n",
       "  0.391708702198478,\n",
       "  0.37013454004518515,\n",
       "  0.3633512782135498,\n",
       "  0.36328641377659493,\n",
       "  0.34733013586321876,\n",
       "  0.33493744977501666,\n",
       "  0.3216406365892272,\n",
       "  0.3168570598178327,\n",
       "  0.3053044385826791,\n",
       "  0.31059415505003574,\n",
       "  0.3022229165029424,\n",
       "  0.27712314161283375,\n",
       "  0.28537051888035814,\n",
       "  0.28084551195091784,\n",
       "  0.28165238905054674,\n",
       "  0.2712692254578381,\n",
       "  0.2761861422994752,\n",
       "  0.27396847333099794,\n",
       "  0.2778741914326194,\n",
       "  0.25900329662157273,\n",
       "  0.26578059179315183,\n",
       "  0.2665852268240345,\n",
       "  0.2695080870027735,\n",
       "  0.26494642428116505,\n",
       "  0.2633997713928538,\n",
       "  0.2627574910105927,\n",
       "  0.2684356239812969,\n",
       "  0.2588936713204455,\n",
       "  0.2635733823278057,\n",
       "  0.25953740227832467,\n",
       "  0.2717317518617299,\n",
       "  0.2627937479504644,\n",
       "  0.2625152746846935],\n",
       " 'dev_loss_history': [1.0392283201217651,\n",
       "  0.7508131861686707,\n",
       "  0.601652204990387,\n",
       "  0.6013156771659851,\n",
       "  0.5404952764511108,\n",
       "  0.5448549389839172,\n",
       "  0.5235238075256348,\n",
       "  0.5005514621734619,\n",
       "  0.473529189825058,\n",
       "  0.5186625719070435,\n",
       "  0.4846130907535553,\n",
       "  0.4922506809234619,\n",
       "  0.4766833782196045,\n",
       "  0.5163813233375549,\n",
       "  0.4879426658153534,\n",
       "  0.45182764530181885,\n",
       "  0.4509797990322113,\n",
       "  0.4620245099067688,\n",
       "  0.4741843342781067,\n",
       "  0.4649021327495575,\n",
       "  0.4663154184818268,\n",
       "  0.4798979163169861,\n",
       "  0.4801459312438965,\n",
       "  0.4897935390472412,\n",
       "  0.47653523087501526,\n",
       "  0.46988824009895325,\n",
       "  0.4671732783317566,\n",
       "  0.4711557924747467,\n",
       "  0.47472083568573,\n",
       "  0.46848422288894653,\n",
       "  0.47812163829803467,\n",
       "  0.47695761919021606,\n",
       "  0.47558075189590454,\n",
       "  0.47201359272003174,\n",
       "  0.4701985716819763,\n",
       "  0.47412025928497314,\n",
       "  0.4756969213485718,\n",
       "  0.4762319028377533,\n",
       "  0.475778728723526,\n",
       "  0.47583886981010437,\n",
       "  0.475521445274353,\n",
       "  0.47555238008499146,\n",
       "  0.4765179455280304,\n",
       "  0.4766770601272583,\n",
       "  0.47676944732666016,\n",
       "  0.477838397026062,\n",
       "  0.4779544174671173,\n",
       "  0.47764354944229126,\n",
       "  0.4779199957847595,\n",
       "  0.4780750572681427]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 50 Epochs\n",
    "from flair.trainers import ModelTrainer\n",
    "#6. initialize trainer\n",
    "trainer : ModelTrainer = ModelTrainer(tagger, corpus)\n",
    "\n",
    "#7.start training(be patient, it takes a while)\n",
    "trainer.train(r'C:\\Users\\Chiara\\Desktop\\CoNLL_project',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              max_epochs=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJgACbQXKtUZ"
   },
   "source": [
    "This sets our model for training.\n",
    "We passed the **validation** as well as the **test data**. That’s because flair internally does a lot of things for you, while training and even post-training. It creates a **new directory called resources** in your current working directory where you will find everything from the logs of training, loss information to the predictions on the test set with a confidence score. Under the same directory our model will be saved.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ut-rcME2LDRX"
   },
   "source": [
    "If one intends to, they can use these weights to visualize as per the documentation. The results(predictions) on the test sets are available in a tab-separated format which can be used to evaluate the model. Anyway, the performance metrics are present there at the end of training.log for each entity label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hgikWnLL-K4"
   },
   "source": [
    "Lastly, we have a trained model and we can now use it to **predict the tags for a new sequence of text**. That again can be done in a couple of lines shown in the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "-HdHpgA_L_yp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-29 14:31:33,942 loading file C:\\Users\\Chiara\\Desktop\\CoNLL_project\\final-model.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "# load the trained model\n",
    "model = SequenceTagger.load(r'C:\\Users\\Chiara\\Desktop\\CoNLL_project\\final-model.pt') \n",
    "\n",
    "# create example sentence\n",
    "sentence = Sentence('Anna is a lady who lives in Brescia, and her husband is called Antonio.' )\n",
    "# predict the tags\n",
    "model.predict(sentence)\n",
    "#print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "CF95Yg6IYROf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anna <B-PER> is a lady who lives in Brescia <B-LOC> , and her husband is called Antonio <B-PER> .\n"
     ]
    }
   ],
   "source": [
    "print(sentence.to_tagged_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "BjQDNcNsjSAX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-29 15:32:39,886 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 15:32:39,887 WARNING: No LOSS found for test split in this data.\n",
      "2021-03-29 15:32:39,888 Are you sure you want to plot LOSS and not another value?\n",
      "2021-03-29 15:32:39,889 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-29 15:32:39,948 ----------------------------------------------------------------------------------------------------\n",
      "2021-03-29 15:32:39,948 WARNING: No F1 found for test split in this data.\n",
      "2021-03-29 15:32:39,950 Are you sure you want to plot F1 and not another value?\n",
      "2021-03-29 15:32:39,950 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss and F1 plots are saved in C:\\Users\\Chiara\\Desktop\\CoNLL_project\\training.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights plots are saved in C:\\Users\\Chiara\\Desktop\\CoNLL_project\\weights.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from flair.visual.training_curves import Plotter\n",
    "#plotter = Plotter()\n",
    "#plotter.plot_training_curves(r'CoNLL_project\\test.tsv') \n",
    "#plotter.plot_weights(r'CoNLL_project\\weights.txt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPbYhkwjMFiB"
   },
   "source": [
    "# CONCLUSION:\n",
    "And that’s how you train the NER model for custom entities using Flair. It is easy to use, just the data preparation was a bit tedious unlike spaCy, where we have tools for that also(PhraseMatcher, etc). Flair is said to achieve better performance than spaCy for sequence tagging. It will be a good practice to first learn to train NER for custom entities with spaCy and then moving to Flair."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ndg6futwMVlx"
   },
   "source": [
    " Sources:\n",
    " * difference between spaCy and Flair NER:\n",
    " https://medium.com/@sapphireduffy/is-flair-a-suitable-alternative-to-spacy-6f55192bfb01 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ElpVzb5PMnC5"
   },
   "source": [
    "* CODE: https://medium.com/thecyphy/training-custom-ner-model-using-flair-df1f9ea9c762"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oryJUAU6N30x"
   },
   "source": [
    "* BEST EMBEDDING + MODEL : https://github.com/flairNLP/flair/blob/master/resources/docs/EXPERIMENTS.md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-p0vc_DUXok"
   },
   "source": [
    "* BIO ANNOTATION: https://books.google.it/books?id=ankSgwPgOUQC&pg=PA297&lpg=PA297&dq=B-ORG+ner&source=bl&ots=X3S2NDYvIQ&sig=ACfU3U0AVwyUgMoXDnY4sS50xJxa5TuCaw&hl=it&sa=X&ved=2ahUKEwjEp5TVlYHqAhWUOcAKHc7QDx0Q6AEwAXoECAoQAQ#v=onepage&q=B-ORG%20ner&f=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NLLc6XxpWSo"
   },
   "source": [
    "* https://www.analyticsvidhya.com/blog/2019/02/flair-nlp-library-python/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "CoNLL2003_FLAIR_training.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "182f4066c27642b58b211612289c27af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "27d097e601a44a46b62d47ca724a1004": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_51a9935a5d8d45cfb501cdc6540f75a5",
       "IPY_MODEL_c67d1b8e46c54c8ea8e263c734f26e92"
      ],
      "layout": "IPY_MODEL_2ca72065e98c4508b6493d88b8d083ae"
     }
    },
    "2a228686038c4a558f794cc855e9d8aa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ca72065e98c4508b6493d88b8d083ae": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2fb07d95d5f94b0bb830f1b9c291a344": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_533bf5168f18464eac9bca781e172202",
      "placeholder": "​",
      "style": "IPY_MODEL_865e9d807af148e1949d863154197479",
      "value": " 232k/232k [00:00&lt;00:00, 314kB/s]"
     }
    },
    "343d7d1cd58f4129954add7f94b26258": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "Downloading:  51%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ffdd165c97a44b7094bc9bce7f53a625",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6bd598f6a12343439d9863f1d93005a9",
      "value": 223884288
     }
    },
    "3bb3e89764b349a9aa3438237c802a03": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "490c0d13e3034530b24769efc54ee050": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "51a9935a5d8d45cfb501cdc6540f75a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2a228686038c4a558f794cc855e9d8aa",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_903fdf14332f4b8fa7ab675f451c3a5f",
      "value": 433
     }
    },
    "533bf5168f18464eac9bca781e172202": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bd598f6a12343439d9863f1d93005a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "865e9d807af148e1949d863154197479": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8aaa8ae9d7574c09b05696bcc2709870": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_182f4066c27642b58b211612289c27af",
      "placeholder": "​",
      "style": "IPY_MODEL_c85150bdaf6d444ab0a64d4962f6ea7c",
      "value": " 224M/440M [00:20&lt;00:02, 89.9MB/s]"
     }
    },
    "903fdf14332f4b8fa7ab675f451c3a5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "97f24f08a89a4e509c5b3dc891d423ad": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3bb3e89764b349a9aa3438237c802a03",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_490c0d13e3034530b24769efc54ee050",
      "value": 231508
     }
    },
    "c10ef35584874e849c23015dfaeb87ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c67d1b8e46c54c8ea8e263c734f26e92": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e8efbd4d62674de6af3932662c711014",
      "placeholder": "​",
      "style": "IPY_MODEL_c10ef35584874e849c23015dfaeb87ea",
      "value": " 433/433 [03:31&lt;00:00, 2.04B/s]"
     }
    },
    "c85150bdaf6d444ab0a64d4962f6ea7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da9b767d5b524e4dabe50048b4e9a70a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1828bd117444dafb6922ca3e03e7f8a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2f9e731f21645d9a3facaaed38bbcdf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_97f24f08a89a4e509c5b3dc891d423ad",
       "IPY_MODEL_2fb07d95d5f94b0bb830f1b9c291a344"
      ],
      "layout": "IPY_MODEL_da9b767d5b524e4dabe50048b4e9a70a"
     }
    },
    "e5d48bfa1646405caf043329f43f595c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_343d7d1cd58f4129954add7f94b26258",
       "IPY_MODEL_8aaa8ae9d7574c09b05696bcc2709870"
      ],
      "layout": "IPY_MODEL_e1828bd117444dafb6922ca3e03e7f8a"
     }
    },
    "e8efbd4d62674de6af3932662c711014": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffdd165c97a44b7094bc9bce7f53a625": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
